[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manual de Estadística",
    "section": "",
    "text": "Prefacio\n¡Bienvenida/os al manual de Estadística!\nEste libro es una introducción a la Estadística básica y el cálculo de probabilidades para alumnos de grados de ciencias e ingenierías.\nEste libro se complementa con los siguientes recursos:"
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Manual de Estadística",
    "section": "Licencia",
    "text": "Licencia\nEsta obra está bajo una licencia Reconocimiento – No comercial – Compartir bajo la misma licencia 3.0 España de Creative Commons. Para ver una copia de esta licencia, visite https://creativecommons.org/licenses/by-nc-sa/3.0/es/.\nCon esta licencia eres libre de:\n\nCopiar, distribuir y mostrar este trabajo.\nRealizar modificaciones de este trabajo.\n\nBajo las siguientes condiciones:\n\n**Reconocimiento Debe reconocer los créditos de la obra de la manera especificada por el autor o el licenciador (pero no de una manera que sugiera que tiene su apoyo o apoyan el uso que hace de su obra).\n**No comercial No puede utilizar esta obra para fines comerciales.\n**Compartir bajo la misma licencia Si altera o transforma esta obra, o genera una obra derivada, sólo puede distribuir la obra generada bajo una licencia idéntica a ésta.\n\nAl reutilizar o distribuir la obra, tiene que dejar bien claro los términos de la licencia de esta obra.\nEstas condiciones pueden no aplicarse si se obtiene el permiso del titular de los derechos de autor.\nNada en esta licencia menoscaba o restringe los derechos morales del autor."
  },
  {
    "objectID": "01-introduccion.html#la-estadística-como-herramienta-científica",
    "href": "01-introduccion.html#la-estadística-como-herramienta-científica",
    "title": "1  Introducción a la Estadística",
    "section": "1.1 La estadística como herramienta científica",
    "text": "1.1 La estadística como herramienta científica\n\n1.1.1 ¿Qué es la estadística?\n\nDefinición 1.1 (Estadística) La estadística es una rama de las matemáticas que se encarga de la recogida, análisis e interpretación de datos.\n\nEl papel de la Estadística es extraer información de los datos para adquirir el conocimiento necesario para tomar decisiones.\n\n\n\nPropósito de la Estadística\n\n\nLa estadística es imprescindible en cualquier disciplina científica o técnica donde se manejen datos, especialmente si son grandes volúmenes de datos, como por ejemplo en Física, Química, Medicina, Psicología, Economía o Ciencias Sociales.\nPero, ¿por qué es necesaria la Estadística?\n\n\n1.1.2 La variabilidad de nuestro mundo\nEl científico trata de estudiar el mundo que le rodea; un mundo que está lleno de variaciones que dificultan la determinación del comportamiento de las cosas.\nLa estadística actúa como disciplina puente entre la realidad del mundo y los modelos matemáticos que tratan de explicarla, proporcionando una metodología para evaluar las discrepancias entre la realidad y los modelos teóricos.\nEsto la convierte en una herramienta indispensable en las ciencias aplicadas que requieran el análisis de datos y el diseño de experimentos."
  },
  {
    "objectID": "01-introduccion.html#población-y-muestra",
    "href": "01-introduccion.html#población-y-muestra",
    "title": "1  Introducción a la Estadística",
    "section": "1.2 Población y muestra",
    "text": "1.2 Población y muestra\n\n1.2.1 Población estadística\n\nDefinición 1.2 (Población) Una población es un conjunto de elementos definido por una o más características que tienen todos los elementos, y sólo ellos. Cada elemento de la población se llama individuo.\n\n\nDefinición 1.3 (Tamaño poblacional) El número de individuos de una población se conoce como tamaño poblacional y se representa como \\(N\\).\n\n\nEjemplo 1.1 En unas elecciones generales a la presidencia del gobierno, la población serían todos los individuos del estado con derecho a voto. En el estudio de una enfermedad, la población sería todas las personas que tienen la enfermedad. Y en un proceso de control de calidad en la fabricación de un fármaco, la población estaría formada por todos los fármacos que se producen en la fábrica.\n\nA veces, no todos los elementos de la población están accesibles para su estudio. Entonces se distingue entre:\n\nPoblación Teórica: Conjunto de elementos a los que se quiere extrapolar los resultados del estudio.\nPoblación Estudiada: Conjunto de elementos realmente accesibles en el estudio.\n\n\nEjemplo 1.2 En el caso del estudio de una enfermedad, la población teórica sería todas las personas que contraigan la enfermedad, incluso si aún no han nacido, mientras que la población estudiada se limitaría al número de personas enfermas que realmente podemos estudiar (obsérvese que incluso quedarían fuera las personas enfermas pero de las que no podemos conseguir información).\n\n\n\n1.2.2 Inconvenientes en el estudio de la población\nEl científico estudia un determinado fenómeno en una población para comprenderlo, obtener conocimiento sobre el mismo, y así poder controlarlo. Pero, para tener un conocimiento completo de la población es necesario estudiar todos los individuos de la misma. Sin embargo, esto no siempre es posible por distintos motivos:\n\nEl tamaño de la población es infinito, o bien es finito pero demasiado grande.\nLas pruebas a que se someten los individuos son destructivas.\nEl coste, tanto de dinero como de tiempo, que supondría estudiar a todos los individuos es excesivo.\n\n\n\n1.2.3 Muestra estadística\nCuando no es posible o conveniente estudiar todos los individuos de la población, se estudia sólo una parte de la misma.\n\nDefinición 1.4 (Muestra) Una muestra es un subconjunto de la población.\n\n\nDefinición 1.5 (Tamaño muestral) Al número de individuos que componen la muestra se le llama tamaño muestral y se representa por \\(n\\).\n\nHabitualmente, el estudio de una población se realiza a partir de muestras extraídas de dicha población.\nGeneralmente, el estudio de la muestra sólo aporta conocimiento aproximado de la población. Pero en muchos casos es suficiente.\n\n\n1.2.4 Determinación del tamaño muestral\nUna de las preguntas más interesantes que surge inmediatamente es: ¿cuántos individuos es necesario tomar en la muestra para tener un conocimiento aproximado pero suficiente de la población?\nLa respuesta depende de varios factores, como la variabilidad de la población o la fiabilidad deseada para las extrapolaciones que se hagan hacia la población.\nPor desgracia no se podrá responder hasta casi el final del curso, pero en general, cuantos más individuos haya en la muestra, más fiables serán las conclusiones sobre la población, pero también será más lento y costoso el estudio.\n\nEjemplo 1.3 Para entender a qué nos referimos cuando hablamos de un tamaño muestral suficiente para comprender lo que ocurre en la población, podemos utilizar el siguiente símil en que se trata de comprender el motivo que representa una fotografía.\nUna fotografía digital está formada por multitud de pequeños puntitos llamados pixels que se dispone en una enorme tabla de filas y columnas (cuantas más filas y columnas haya se habla de que la foto tiene más resolución). Aquí la población estaría formada por todos y cada uno de los píxeles que forman la foto. Por otro lado cada pixel tiene un color y es la variedad de colores a lo largo de los pixels la que permite formar la imagen de la fotografía.\n¿Cuántos píxeles debemos tomar en una muestra para averiguar la imagen de la foto?\nLa respuesta depende de la variabilidad de colores en la foto. Si todos los pixels de la foto son del mismo color, entonces un sólo pixel basta para desvelar la imagen. Pero, si la foto tiene mucha variabilidad de colores, necesitaremos muchos más pixels en la muestra para descubrir el motivo de la foto.\nLa imagen siguiente contiene una muestra pequeña de píxeles de una foto. ¿Puedes averiguar el motivo de a foto?\n\n\n\nMuestra pequeña de píxeles de una foto.\n\n\n¡Con una muestra pequeña es difícil averiguar el contenido de la imagen!\nSeguramente no has podido averiguar el motivo de la fotografía, porque en este caso el número de píxeles que hemos tomado en la muestra es insuficiente para comprender toda la variabilidad de colores que hay en la foto.\nLa siguiente imagen contiene una muestra mayor de píxeles. ¿Eres capaz de adivinar el motivo de la foto ahora?\n\n\n\nMuestra mayor de píxeles de una foto.\n\n\n¡Con una muestra mayor es posible desvelar el motivo de la foto!\nY aquí está la población completa.\n\n\n\nPoblación de píxeles de una foto.\n\n\nLo importante es que ¡No es necesario conocer todos los píxeles para averiguar la imagen!\n\n\n\n1.2.5 Tipos de razonamiento\nAsí pues, habitualmente realizaremos el estudio de la población a partir de muestras y luego trataremos de extrapolar lo observado en la muestra al resto de la población. A este tipo de razonamiento que saca conclusiones desde la muestra hacia la población se le conoce como razonamiento inductivo.\n\n\n\nTipos de razonamiento.\n\n\n\nCaracterísticas de la deducción: Si las premisas son ciertas, garantiza la certeza de las conclusiones (es decir, si algo se cumple en la población, también se cumple en la muestra). Sin embargo, ¡no aporta conocimiento nuevo!\nCaracterísticas de la inducción: No garantiza la certeza de las conclusiones (si algo se cumple en la muestra, puede que no se cumpla en la población, así que ¡cuidado con las extrapolaciones!), pero ¡es la única forma de generar conocimiento nuevo!\n\nLa estadística se apoya fundamentalmente en el razonamiento inductivo ya que utiliza la información obtenida a partir de muestras para sacar conclusiones sobre las poblaciones. A diferencia del razonamiento deductivo que va de lo general a lo particular, o en nuestro caso de la población a la muestra, el razonamiento inductivo no garantiza la certeza de las conclusiones, por lo que debemos ser cuidadosos a la hora de generalizar sobre la población lo observado en al muestra, ya que si la muestra no es representativa de la población o contiene sesgos, las conclusiones pueden ser erróneas."
  },
  {
    "objectID": "01-introduccion.html#muestreo",
    "href": "01-introduccion.html#muestreo",
    "title": "1  Introducción a la Estadística",
    "section": "1.3 Muestreo",
    "text": "1.3 Muestreo\n\nDefinición 1.6 (Muestreo) El proceso de selección de los elementos que compondrán una muestra se conoce como muestreo.\n\n[](img/introduccion/muestreo.svg” alt=“Muestreo” width=“500px”&gt;\nPara que una muestra refleje información fidedigna sobre la población global debe ser representativa de la misma, lo que significa que debe reproducir a pequeña escala la variabilidad de la población.\nEl objetivo es obtener una muestra representativa de la población.\n\n1.3.1 Modalidades de muestreo\nExisten muchas técnicas de muestreo pero se pueden agrupar en dos categorías:\n\nMuestreo Aleatorio: Elección aleatoria de los individuos de la muestra. Todos tienen la misma probabilidad de ser elegidos (equiprobabilidad).\nMuestreo No Aleatorio: Los individuos se eligen de forma no aleatoria. Algunos individuos tienen más probabilidad de ser seleccionados que otros.\n\nSólo las técnicas aleatorias evitan el sesgo de selección, y por tanto, garantizan la representatividad de la muestra extraída, y en consecuencia la validez de las conclusiones.\nLas técnicas no aleatorias no sirven para hacer generalizaciones, ya que no garantizan la representatividad de la muestra. Sin embargo, son menos costosas y pueden utilizarse en estudios exploratorios.\n\n\n1.3.2 Muestreo aleatorio simple\nDentro de las modalidades de muestreo aleatorio, el tipo más conocido es el muestreo aleatorio simple, caracterizado por:\n\nTodos los individuos de la población tienen la misma probabilidad de ser elegidos para la muestra.\nLa selección de individuos es con reemplazamiento, es decir, cada individuo seleccionado es devuelto a la población antes de seleccionar al siguiente (y por tanto no se altera la población de partida).\nLas sucesivas selecciones de un individuo son independientes.\n\nLa única forma de realizar un muestreo aleatorio es asignar un número a cada individuo de la población (censo) y realizar un sorteo aleatorio.\n\n\n1.3.3 Variables estadísticas\nTodo estudio estadístico comienza por la identificación de las características que interesa estudiar en la población y que se medirán en los individuos de la muestra.\n\nDefinición 1.7 (Variable estadística) Una variable estadística es una propiedad o característica medida en los individuos de la población.\nLos datos son los valores observados en las variables estadísticas.\n\n\n\n\nVariables estadísticas.\n\n\nEstas características pueden ser de distintos tipos de acuerdo a su naturaleza y su escala:\n\nVariables cualitativas o atributos: Miden cualidades no numéricas. Pueden ser:\n\nNominales: No existe un orden entre las categorías.\nEjemplo: El color de pelo o el sexo.\nOrdinales: Existe un orden entre las categorías. Ejemplo: El nivel de estudios o la gravedad de una enfermedad.\n\nVariables cuantitativas: Miden cantidades numéricas. Pueden ser:\n\nDiscretas: Toman valores numéricos aislados (habitualmente números enteros).\nEjemplo: El número de hijos o el número de coches en una familia.\nContinuas: Pueden tomar cualquier valor en un intervalo real.\nEjemplo: El peso o la estatura.\n\n\nLas variables cualitativas y discretas se conocen también con variables categóricas y sus valores categorías.\n\n\n\nTipos de variables estadísticas.\n\n\n\n1.3.3.1 Elección del tipo de variable más apropiado\nEn ocasiones una característica puede medirse mediante variables de distinto tipo.\n\nEjemplo 1.4 Si una persona fuma o no podría medirse de diferentes formas:\n\nFuma: si/no. (Nominal)\nNivel de fumador: No fuma / ocasional / moderado / bastante / empedernido. (Ordinal)\nNúmero de cigarros diarios: 0,1,2,… (Discreta)\n\n\nEn estos casos es preferible usar variables cuantitativas a cualitativas. Dentro de las cuantitativas es preferible usar las continuas a las discretas y dentro de las cualitativas es preferible usar ordinales a nominales pues aportan más información.\n\n\n\nCantidad de información de los tipos de variables estadísticas.\n\n\nDe acuerdo al papel que juegan en el estudio las variables también pueden clasificarse como:\n\nVariables independientes: Variables que supuestamente no dependen de otras variables en el estudio. Habitualmente son las variables manipuladas en el experimento para ver su efecto en las variables dependientes. Se conocen también como variables predictivas.\nVariables dependientes: Variables que supuestamente dependen de otras variables en el estudio. No son manipuladas en el experimento y también se conocen como variables respuesta.\n\n\nEjemplo 1.5 En un estudio sobre el rendimiento de los alumnos de un curso, la inteligencia de los alumnos y el número de horas de estudio diarias serían variables independientes y la nota del curso sería una variable dependiente.\n\n\n\n\n1.3.4 Tipos de estudios estadísticos\nDependiendo de si se manipulan las variables independientes existen dos tipos de estudios:\n\nExperimentales: Cuando las variables independientes son manipuladas para ver el efecto que producen en las variables dependientes.\n\n\nEjemplo 1.6 En un estudio sobre el rendimiento de los estudiantes en un test, el profesor manipula la metodología de estudio para crear dos o más grupos con metodologías de estudio distintas.\n\n\nNo experimentales: Cuando las variables independientes no son manipuladas. Esto no significa que sea imposible hacerlo, sino que es difícil o poco ético hacerlo.\n\n\nEjemplo 1.7 En un estudio un investigador puede estar interesado en el efecto de fumar sobre el cáncer de pulmón. Aunque es posible, no sería ético pedirle a los pacientes que fumasen para ver el efecto que tiene sobre sus pulmones. En este caso, el investigador podría estudiar dos grupos de pacientes, uno con cáncer de pulmón y otro sin cáncer, y observar en cada grupo cuántos fuman o no.\n\nLos estudios experimentales permiten identificar causas y efectos entre las variables del estudio, mientras que los no experimentales sólo permiten identificar relaciones de asociación entre las variables.\n\n\n1.3.5 La tabla de datos\nLas variables a estudiar se medirán en cada uno de los individuos de la muestra, obteniendo un conjunto de datos que suele organizarse en forma de matriz que se conoce como tabla de datos_.\nEn esta tabla cada columna contiene la información de una variable y cada fila la información de un individuo.\n\nEjemplo 1.8 La siguiente tabla contiene información de las variables Nombre, Edad, Sexo, Peso y Altura de una muestra de 6 personas.\n\n\n\nNombre\nEdad\nSexo\nPeso(Kg)\nAltura(cm)\n\n\n\n\nJosé Luis Martínez\n18\nH\n85\n179\n\n\nRosa Díaz\n32\nM\n65\n173\n\n\nJavier García\n24\nH\n71\n181\n\n\nCarmen López\n35\nM\n65\n170\n\n\nMarisa López\n46\nM\n51\n158\n\n\nAntonio Ruiz\n68\nH\n66\n174\n\n\n\n\n\n\n1.3.6 Fases del análisis estadístico\nNormalmente un estudio estadístico pasa por las siguientes etapas:\n\nEl estudio comienza por el diseño previo del mismo en el que se establezcan los objetivos del mismo, la población, las variables que se medirán y el tamaño muestral requerido.\nA continuación se seleccionará una muestra representativa del tamaño establecido y se medirán las variables en los individuos de la muestra obteniendo la tabla de datos. De esto se encarga el Muestreo.\nEl siguiente paso consiste en describir y resumir la información que contiene la muestra. De esto se encarga la Estadística Descriptiva.\nLa información obtenida es proyectada sobre un modelo matemático que intenta explicar el comportamiento de la población y el modelo se valida. De todo esto se encarga la Estadística Inferencial.\nFinalmente, el modelo validado nos permite hacer predicciones y sacar conclusiones sobre la población de partida con cierta confianza.\n\n\n1.3.6.1 El ciclo estadístico\n\n\n\nEl ciclo estadístico."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#distribución-de-frecuencias",
    "href": "02-estadistica-descriptiva.html#distribución-de-frecuencias",
    "title": "2  Estadística Descriptiva",
    "section": "2.1 Distribución de frecuencias",
    "text": "2.1 Distribución de frecuencias\nEl estudio de una variable estadística comienza por medir la variable en los individuos de la muestra y clasificar los valores obtenidos.\nExisten dos formas de clasificar estos valores:\n\nSin agrupar: Ordenar todos los valores obtenidos en la muestra de menor a mayor. Se utiliza con atributos y variables discretas con pocos valores diferentes.\nAgrupados: Agrupar los valores en clases (intervalos) y ordenar dichas clases de menor a mayor. Se utiliza con variables continuas y con variables discretas con muchos valores diferentes.\n\n\n2.1.1 Clasificación de la muestra\nConsiste colocar juntos los valores iguales y ordenarlos si existe un orden entre ellos.\n\n\n\nClasificación de la muestra.\n\n\n\n\n2.1.2 Recuento de frecuencias\n\n\n\nRecuento de frecuencias"
  },
  {
    "objectID": "02-estadistica-descriptiva.html#frecuencias-muestrales",
    "href": "02-estadistica-descriptiva.html#frecuencias-muestrales",
    "title": "2  Estadística Descriptiva",
    "section": "2.2 Frecuencias muestrales",
    "text": "2.2 Frecuencias muestrales\n\nDefinición 2.1 (Frecuencias muestrales) Dada una muestra de tamaño \\(n\\) de una variable \\(X\\), para cada valor de la variable \\(x_i\\) observado en la muestra, se define\n\nFrecuencia Absoluta \\(n_i\\): Es el número de veces que el valor \\(x_i\\) aparece en la muestra.\nFrecuencia Relativa \\(f_i\\): Es la proporción de veces que el valor \\(x_i\\) aparece en la muestra. \\[f_i = \\frac{n_i}{n}\\]\nFrecuencia Absoluta Acumulada \\(N_i\\): Es el número de valores en la muestra menores o iguales que \\(x_i\\). \\[N_i = n_1 + \\cdots + n_i = N_{i-1}+n_i\\]\nFrecuencia Relativa Acumulada \\(F_i\\): Es la proporción de valores en la muestra menores o iguales que \\(x_i\\). \\[F_i = \\frac{N_i}{n}\\]\n\n\n\n2.2.1 Tabla de frecuencias\nAl conjunto de valores observados en la muestra junto a sus respectivas frecuencias se le denomina distribución de frecuencias y suele representarse mediante una tabla de frecuencias.\n\n\n\n\n\n\n\n\n\n\nValores de \\(X\\)\nFrecuencia Absoluta\nFrecuencia Relativa\nFrecuencia Absoluta Acumulada\nFrecuencia Relativa Acumulada\n\n\n\n\n\\(x_1\\)\n\\(n_1\\)\n\\(f_1\\)\n\\(N_1\\)\n\\(F_1\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(x_i\\)\n\\(n_i\\)\n\\(f_i\\)\n\\(N_i\\)\n\\(F_i\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(x_k\\)\n\\(n_k\\)\n\\(f_k\\)\n\\(N_k\\)\n\\(F_k\\)\n\n\n\n\nEjemplo 2.1 (Variable cuantitativa y datos no agrupados) El número de hijos en 25 familias es:\n\n1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2\n\nLa tabla de frecuencias del número de hijos en esta muestra es\n\\[\n\\begin{array}{rrrrr}\n\\hline\nx_i & n_i & f_i & N_i & F_i\\\\\n\\hline\n0 & 2 & 0.08 & 2 & 0.08\\\\\n1 & 6 & 0.24 & 8 & 0.32\\\\\n2 & 14 & 0.56 & 22 & 0.88\\\\\n3 & 2 & 0.08 & 24 & 0.96\\\\\n4 & 1 & 0.04 & 25 & 1 \\\\\n\\hline\n\\sum & 25 & 1 \\\\\n\\hline\n\\end{array}\n\\]\n\n\nEjemplo 2.2 (Variable cuantitativa y datos agrupados) Se ha medido la estatura (en cm) de 30 universitarios obteniendo:\n\n179, 173, 181, 170, 158, 174, 172, 166, 194, 185, 162, 187, 198, 177, 178, 165, 154, 188, 166, 171, 175, 182, 167, 169, 172, 186, 172, 176, 168, 187.\n\nLa tabla de frecuencias de la estatura en a esta muestra es\n\\[\n\\begin{array}{crrrr}\n\\hline\nx_i & n_i & f_i & N_i & F_i\\\\\n\\hline\n(150,160] & 2 & 0.07 & 2 & 0.07\\\\\n(160,170] & 8 & 0.27 & 10 & 0.34\\\\\n(170,180] & 11 & 0.36 & 21 & 0.70\\\\\n(180,190] & 7 & 0.23 & 28 & 0.93\\\\\n(190,200] & 2 & 0.07 & 30 & 1 \\\\\n\\hline\n\\sum & 30 & 1 \\\\\n\\hline\n\\end{array}\n\\]\n\n\n\n2.2.2 Construcción de clases\nCada intervalo de agrupación de datos se denomina clase y el centro del intervalo se llama marca de clase.\nA la hora de agrupar los datos en clases hay que tener en cuenta lo siguiente:\n\nEl número de intervalos no debe ser muy grande ni muy pequeño. Una regla orientativa es tomar un número de intervalos próximo a \\(\\sqrt{n}\\) o \\(\\log_2(n)\\).\nLos intervalos no deben solaparse y deben cubrir todo el rango de valores. Es indiferente si se abren por la izquierda y se cierran por la derecha o al revés.\nEl valor más pequeño debe caer dentro del primer intervalo y el más grande dentro del último.\n\n\nEjemplo 2.3 (Variable cualitativa) Los grupos sanguíneos de una muestra de 30 personas son:\n\nA, B, B, A, AB, 0, 0, A, B, B, A, A, A, A, AB, A, A, A, B, 0, B, B, B, A, A, A, 0, A, AB, 0.\n\nLa tabla de frecuencias del grupo sanguíneo en esta muestra es\n\\[\n\\begin{array}{crr}\n\\hline\nx_i & n_i & f_i \\\\\n\\hline\n\\mbox{0} & 5 & 0.16 \\\\\n\\mbox{A} & 14 & 0.47 \\\\\n\\mbox{B} & 8 & 0.27 \\\\\n\\mbox{AB} & 3 & 0.10 \\\\\n\\hline\n\\sum & 30 & 1 \\\\\n\\hline\n\\end{array}\n\\]\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nObsérvese que en este caso las frecuencias acumuladas no tienen sentido al no existir un orden entre los valores de la variable."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#representaciones-gráficas",
    "href": "02-estadistica-descriptiva.html#representaciones-gráficas",
    "title": "2  Estadística Descriptiva",
    "section": "2.3 Representaciones gráficas",
    "text": "2.3 Representaciones gráficas\nLa tabla de frecuencias también suele representarse gráficamente. Dependiendo del tipo de variable y de si se han agrupado o no los datos, se utilizan distintos tipos de gráficos:\n\nDiagrama de barras\nHistograma\nDiagrama de líneas o polígonos.\nDiagrama de sectores.\n\n\n2.3.1 Diagrama de barras\nUn diagrama de barras consiste en un conjunto de barras, una para cada valor o categoría de la variable, dibujadas sobre unos ejes cartesianos.\nHabitualmente los valores o categorías de la variable se representan en eje \\(X\\), y las frecuencias en el eje \\(Y\\). Para cada valor o categoría se dibuja una barra con la altura correspondiente a su frecuencia. La anchura de la barra no es importante pero las barras deben aparecer claramente separadas unas de otras.\nDependiendo del tipo de frecuencia representada en el eje \\(Y\\) se tienen diferentes tipos de diagramas de barras.\nEn ocasiones se dibuja un polígono, conocido como polígono de frecuencias, uniendo mediante segmentos los puntos más altos de cada barra.\n\nEjemplo 2.4 El diagrama de barras que aparece a continuación muestra la distribución de frecuencias absolutas del número de hijos en la muestra anterior.\n\n\n\n\n\nY a continuación se muestra el polígono de frecuencias.\n\n\n\n\n\nEl diagrama de barras que aparece a continuación muestra la distribución de frecuencias relativas del número de hijos en la muestra anterior.\n\n\n\n\n\nEl diagrama de barras que aparece a continuación muestra la distribución de frecuencias absolutas acumuladas del número de hijos en la muestra anterior.\n\n\n\n\n\nY el diagrama de barras que aparece a continuación muestra la distribución de frecuencias relativas acumuladas del número de hijos en la muestra anterior.\n\n\n\n\n\nFinalmente, el último diagrama muestra el polígono de frecuencias relativas acumuladas.\n\n\n\n\n\n\n\n\n2.3.2 Histograma\nUn histograma es similar a un diagrama de barras pero para datos agrupados.\nHabitualmente las clases o intervalos de agrupación se representan en el eje \\(X\\), y las frecuencias en el eje \\(Y\\). Para cada clase se dibuja una barra de altura la correspondiente frecuencia. A diferencia del diagrama de barras, la anchura del la barra coincide con la anchura de las clases y no hay separación entre dos barras consecutivas.\n\n\n\nClasifiación en clases.\n\n\nDependiendo del tipo de frecuencia representada en el eje \\(Y\\) existen distintos tipos de histogramas.\nAl igual que con el diagrama de barras, se puede dibujar un polígono de frecuencias uniendo los puntos centrales más altos de cada barra con segmentos.\n\nEjemplo 2.5 El siguiente histograma muestra la distribución de frecuencias absolutas de las estaturas.\n\n\n\n\n\nEl siguiente histograma muestra la distribución de frecuencias relativas con el polígono de frecuencias.\n\n\n\n\n\n\nEl polígono de frecuencias acumuladas (absolutas o relativas) se conoce como ojiva.\n\nEjemplo 2.6 El histograma y la ojiva siguientes muestran la distribución de frecuencias relativas acumuladas de estaturas.\n\n\n\n\n\n\nObsérvese que en la ojiva se unen los vértices superiores derechos de cada barra con segmentos, en lugar de los puntos centrales, ya que no se consigue alcanzar la frecuencia acumulada correspondiente a la clase hasta que no se alcanza el final del intervalo.\n\n\n2.3.3 Diagrama de sectores\nUn diagrama de sectores consiste en un círculo divido en porciones, uno por cada valor o categoría de la variable. Cada porción se conoce como sector y su ángulo o área es proporcional a la correspondiente frecuencia del valor o categoría.\nLos diagramas de sectores pueden representar frecuencias absolutas o relativas, pero no pueden representar frecuencias acumuladas, y se utilizan sobre todo con atributos nominales. Para atributos ordinales o variables cuantitativas es mejor utilizar diagramas de barras, ya es más fácil percibir las diferencias en una dimensión (altura de las barras) que en dos dimensiones (áreas de los sectores).\n\nEjemplo 2.7 El diagrama de sectores siguiente muestra la distribución de frecuencias relativas de los grupos sanguíneos.\n\n\n\n\n\n\n\n\n2.3.4 La distribución Normal\nLas distribuciones con diferentes propiedades presentan formas distintas.\n\nEjemplo 2.8 (Distribución de los ingresos familiares)  \n\n\n\n\n\n\n\nEjemplo 2.9 (Distribución de la edad de fallecimiento)  \n\n\n\n\n\n\n\nEjemplo 2.10 (Distribución del tiempo de espera del metro)  \n\n\n\n\n\n\n\nEjemplo 2.11 (Distribución del tiempo de llegada de clientes a un restaurante)  \n\n\n\n\n\n\nLas distribuciones con forma de campana se presentan muy a menudo en las variables biológicas.\n\nEjemplo 2.12 (Distribución del peso de los hombres)  \n\n\n\n\n\n\n\nEjemplo 2.13 (Distribución de la estatura de las mujeres)  \n\n\n\n\n\n\n\nEjemplo 2.14 (Distribución de la estatura según el sexo)  \n\n\n\n\n\n\n\nEjemplo 2.15 (Distribución de la estatura de hombres y mujeres)  \n\n\n\n\n\n\n\nEjemplo 2.16 (Distribución del colesterol)  \n\n\n\n\n\n\n\nEjemplo 2.17 (Distribución de notas)  \n\n\n\n\n\n\nLa distribución con forma de campana aparece tan a menudo en la Naturaleza que se conoce como distribución normal o distribución gaussiana.\n\n\n\nCampana de Gauss."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#datos-atípicos",
    "href": "02-estadistica-descriptiva.html#datos-atípicos",
    "title": "2  Estadística Descriptiva",
    "section": "2.4 Datos atípicos",
    "text": "2.4 Datos atípicos\nUno de los principales problemas de las muestras son los datos atípicos, que son valores de la variable que se diferencian mucho del resto de los valores en la muestra.\n\n\n\nDato atípico.\n\n\nEs muy importante detectar los datos atípicos antes de realizar cualquier análisis de los datos, pues suelen distorsionar los resultados.\nAparecen siempre en los extremos de la distribución, y pueden detectarse con un diagrama de caja y bigotes (tal y como veremos más adelante).\n\n2.4.1 Tratamiento de los datos atípicos\nCuando trabajemos con muestras grandes, los datos atípicos tienen menor influencia y pueden dejarse en la muestra.\nCuando trabajemos con muestras pequeñas tenemos varias opciones:\n\nEliminar el dato atípico si se trata de un error.\nSustituir el dato atípico por el menor o el mayor valor de la distribución que no es atípico si no se trata de un error y el dato atípico no concuerda con la distribución teórica.\nDejar el dato atípico si no es un error, y cambiar el modelo de distribución teórico para adecuarlo a los datos atípicos."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#estadísticos-muestrales",
    "href": "02-estadistica-descriptiva.html#estadísticos-muestrales",
    "title": "2  Estadística Descriptiva",
    "section": "2.5 Estadísticos muestrales",
    "text": "2.5 Estadísticos muestrales\nLa tabla de frecuencias sintetiza la información de la distribución de valores de la variable estudiada en la muestra, pero en muchas ocasiones es insuficiente para describir determinados aspectos de la distribución, como por ejemplo, cuáles son los valores más representativos de la muestra, cómo es la variabilidad de los datos, qué datos pueden considerarse atípicos, o cómo es la simetría de la distribución.\nPara describir esos aspectos de la distribución muestral se utilizan unas medidas resumen llamadas estadísticos muestrales.\nDe acuerdo al aspecto de las distribución que miden, existen diferentes tipos de estadísticos:\nEstadísticos de Posición: Miden los valores en torno a los que se agrupan los datos o que dividen la distribución en partes iguales.\nEstadísticos de Dispersión: Miden la heterogeneidad de los datos.\nEstadísticos de Forma: Miden aspectos de la forma que tiene la distribución de los datos, como la simetría o el apuntamiento."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#estadísticos-de-posición",
    "href": "02-estadistica-descriptiva.html#estadísticos-de-posición",
    "title": "2  Estadística Descriptiva",
    "section": "2.6 Estadísticos de posición",
    "text": "2.6 Estadísticos de posición\nPueden ser de dos tipos:\nEstadísticos de Tendencia Central: Determinan valores alrededor de los cuales se concentran los datos, habitualmente en el centro de la distribución. Estas medidas suelen utilizarse como valores representativos de la muestra. Las más importantes son:\n\nMedia aritmética\nMediana\nModa\n\nEstadísticos de Posición no centrales: Dividen la distribución en partes con el mismo número de datos. Las más importantes son:\n\nCuartiles.\nDeciles.\nPercentiles.\n\n\n2.6.1 Media aritmética\n\nDefinición 2.2 (Media aritmética muestral \\(\\bar{x}\\)) La media aritmética muestral de una variable \\(X\\) es la suma de los valores observados en la muestra dividida por el tamaño muestral\n\\[\\bar{x} = \\frac{\\sum x_i}{n}\\]\n\nA partir de la tabla de frecuencias puede calcularse con la fórmula\n\\[\\bar{x} = \\frac{\\sum x_in_i}{n} = \\sum x_i f_i\\]\nEn la mayoría de los casos, la media aritmética es la medida que mejor representa a la muestra.\n\n\n\n\n\n\nAdvertencia\n\n\n\nNo puede calcularse para variables cualitativas.\n\n\n\nEjemplo 2.18 (Datos no agrupados) Utilizando los datos de la muestra del número de hijos en las familias, la media aritmética es\n\\[\n\\begin{aligned}\n\\bar{x} &= \\frac{1+2+4+2+2+2+3+2+1+1+0+2+2}{25}+\\\\\n&+\\frac{0+2+2+1+2+2+3+1+2+2+1+2}{25} = \\frac{44}{25} = 1.76 \\mbox{ hijos}.\n\\end{aligned}\n\\]\no bien, desde la tabla de frecuencias\n\\[\n\\begin{array}{rrrrr}\n\\hline\nx_i & n_i & f_i & x_in_i & x_if_i\\\\\n\\hline\n0 & 2 & 0.08 & 0 & 0\\\\\n1 & 6 & 0.24 & 6 & 0.24\\\\\n2 & 14 & 0.56 & 28 & 1.12\\\\\n3 & 2  & 0.08 & 6 & 0.24\\\\\n4 & 1 & 0.04 & 4 & 0.16 \\\\\n\\hline\n\\sum & 25 & 1 & 44 & 1.76 \\\\\n\\hline\n\\end{array}\n\\]\n\\[\n\\bar{x} = \\frac{\\sum x_in_i}{n} = \\frac{44}{25}= 1.76 \\mbox{ hijos}\\qquad \\bar{x}=\\sum{x_if_i} = 1.76 \\mbox{ hijos}.\n\\]\nEsto significa que el valor que mejor representa el número de hijos en las familias de la muestra es 1.76 hijos.\n\n\nEjemplo 2.19 (Datos agrupados) Utilizando los datos de la muestra de estaturas, la media es\n\\[\n\\bar{x} = \\frac{179+173+\\cdots+187}{30} = 175.07 \\mbox{ cm}.\n\\]\no bien, desde la tabla de frecuencias utilizando las marcas de clase \\(x_i\\):\n\\[\n\\begin{array}{crrrrr}\n\\hline\nX & x_i & n_i & f_i & x_in_i & x_if_i\\\\\n\\hline\n(150,160] & 155 & 2 & 0.07 & 310 & 10.33\\\\\n(160,170] & 165 & 8 & 0.27 & 1320 & 44.00\\\\\n(170,180] & 175 & 11 & 0.36 & 1925 & 64.17\\\\\n(180,190] & 185 & 7 & 0.23 & 1295 & 43.17\\\\\n(190,200] & 195 & 2 & 0.07 & 390 & 13 \\\\\n\\hline\n\\sum &  & 30 & 1 & 5240 & 174.67 \\\\\n\\hline\n\\end{array}\n\\]\n\\[\n\\bar{x} = \\frac{\\sum x_in_i}{n} = \\frac{5240}{30}= 174.67 \\mbox{ cm} \\qquad \\bar{x}=\\sum{x_if_i} = 174.67 \\mbox{ cm}.\n\\]\nObsérvese que al calcular la media desde la tabla de frecuencias el resultado difiere ligeramente del valor real obtenido directamente desde la muestra, ya que los valores usados en los cálculos no son los datos reales sino las marcas de clase.\n\n\n2.6.1.1 Media ponderada\nEn algunos casos, los valores de la muestra no tienen la misma importancia. En este caso la importancia o peso de cada valor de la muestra debe tenerse en cuenta al calcular la media.\n\nDefinición 2.3 (Media ponderada muestral \\(\\bar x_p\\)) Dada una muestra de valores \\(x_1,\\ldots, x_n\\) donde cada valor \\(x_i\\) tiene asociado un peso \\(p_i\\), la media ponderada muestral de la variable \\(X\\) es la suma de los productos de cada valor observado en la muestra por su peso, dividida por la suma de todos los pesos\n\\[\\bar{x}_p = \\frac{\\sum x_ip_i}{\\sum p_i}\\]\n\nA partir de la tabla de frecuencias puede calcularse con la fórmula\n\\[\\bar{x}_p = \\frac{\\sum x_ip_in_i}{\\sum p_i}\\]\n\nEjemplo 2.20 Supóngase que un estudiante quiere calcular una medida que represente su rendimiento en el curso. La nota obtenida en cada asignatura y sus créditos son\n\n\n\nAsignatura\nCréditos\nNota\n\n\n\n\nMatemáticas\n6\n5\n\n\nEconomía\n4\n3\n\n\nQuímica\n8\n6\n\n\n\nLa media aritmética vale\n\\[\\bar{x} = \\frac{\\sum x_i}{n} = \\frac{5+3+6}{3}= 4.67 \\text{ puntos}.\\]\nSin embargo, esta nota no representa bien el rendimiento académico del alumno ya que no todas las asignaturas tienen la misma importancia ni requieren el mismo esfuerzo para aprobar. Las asignaturas con más créditos requieren más trabajo y deben tener más peso en el cálculo de la media.\nEs más lógico usar la media ponderada como medida del rendimiento del estudiante, tomando como pesos los créditos de cada asignatura\n\\[\n\\bar{x}_p = \\frac{\\sum x_ip_i}{\\sum p_i} = \\frac{5\\cdot 6+3\\cdot 4+6\\cdot 8}{6+4+8}= \\frac{90}{18} = 5 \\text{ puntos}.\n\\]\n\n\n\n\n2.6.2 Mediana\n\nDefinición 2.4 (Mediana muestral \\(Me\\)) La mediana muestral de una variable \\(X\\) es el valor de la variable que está en el medio de la muestra ordenada.\n\nLa mediana divide la distribución de la muestra en dos partes iguales, es decir, hay el mismo número de valores por debajo y por encima de la mediana. Por tanto, tiene frecuencias acumuladas \\(N_{Me}= n/2\\) y \\(F_{Me}= 0.5\\).\n\n\n\n\n\n\nAdvertencia\n\n\n\nNo puede calcularse para variables nominales.\n\n\nCon datos no agrupados pueden darse varios casos:\n\nTamaño muestral impar: La mediana es el valor que ocupa la posición \\(\\frac{n+1}{2}\\).\nTamaño muestral par: La mediana es la media de los valores que ocupan las posiciones \\(\\frac{n}{2}\\) y \\(\\frac{n}{2}+1\\).\n\n\n\n\nCálculo de la mediana con datos no agrupados.\n\n\n:::{#exm-mediana-datos-no-agrupados} Utilizando los datos del número de hijos de las familias, el tamaño muestral es 25, que es impar, y la mediana es el valor que ocupa la posición \\(\\frac{25+1}{2} = 13\\) de la muestra ordenada.\n\\[\n0,0,1,1,1,1,1,1,2,2,2,2,\\fbox{2},2,2,2,2,2,2,2,2,2,3,3,4\n\\]\ny la mediana es 2 hijos.\nSi se trabaja con la tabla de frecuencias, la mediana es el valor más pequeño con una frecuencia acumulada mayor o igual a \\(13\\), o con una frecuencia relativa acumulada mayor o igual que \\(0.5\\).\n\\[\n\\begin{array}{rrrrr}\n\\hline\nx_i & n_i & f_i & N_i & F_i\\\\\n\\hline\n0 & 2 & 0.08 & 2 & 0.08\\\\\n1 & 6 & 0.24 & 8 & 0.32\\\\\n\\color{red}2 & 14 & 0.56 & 22 & 0.88\\\\\n3 & 2  & 0.08 & 24 & 0.96\\\\\n4 & 1 & 0.04 & 25 & 1 \\\\\n\\hline\n\\sum & 25 & 1 \\\\\n\\hline\n\\end{array}\n\\]\n\n2.6.2.1 Cálculo de la mediana con datos agrupados\nCon datos agrupados la mediana se calcula interpolando en el polígono de frecuencias relativas acumuladas para el valor 0.5.\n\n\n\nCálculo de la mediana con datos agrupados.\n\n\nAmbas expresiones son iguales ya que el ángulo \\(\\alpha\\) es el mismo, y resolviendo la ecuación se tiene la siguiente fórmula para calcular la mediana\n\\[\nMe=l_i+\\frac{0.5-F_{i-1}}{F_i-F_{i-1}}(l_i-l_{i-1})=l_i+\\frac{0.5-F_{i-1}}{f_i}a_i\n\\]\n\nEjemplo 2.21 (Datos agrupados) Utilizando los datos de la muestra de las estaturas de estudiantes, la mediana cae en la clase (170,180].\n\n\n\nEjemplo de cálculo de la mediana con datos agrupados.\n\n\nInterpolando en el intervalo (170,180] se tiene\n\n\n\nEjemplo de cálculo de la mediana con datos agrupados.\n\n\nIgualando ambas expresiones y resolviendo la ecuación se obtiene\n\\[\nMe= 170+\\frac{0.5-0.34}{0.7-0.34}(180-170)=170+\\frac{0.16}{0.36}10=174.54 \\mbox{ cm}.\n\\]\nEsto significa que la mitad de los estudiantes tienen estaturas menores o iguales que 174.54 cm y la otra mitad mayores o iguales.\n\n\n\n\n2.6.3 Moda\n\nDefinición 2.5 (Moda muestral \\(Mo\\)) La moda muestral de una variable \\(X\\) es el valor de la variable más frecuente en la muestra.\n\nCon datos agrupados la clase modal es la clase con mayor frecuencia en la muestra.\nPuede calcularse para todos los tipos de variables (cuantitativas y cualitativas).\nLas distribuciones pueden tener más de una moda.\n\n\n\nCálculo de la moda.\n\n\n\nEjemplo 2.22 Utilizando los datos de la muestra del número de hijos en las familias, el valor con mayor frecuencia es 2, y por tanto la moda es \\(Mo=2\\).\n\\[\n\\begin{array}{rr}\n\\hline\nx_i & n_i \\\\\n\\hline\n0 & 2 \\\\\n1 & 6 \\\\\n\\color{red} 2 & 14 \\\\\n3 & 2  \\\\\n4 & 1 \\\\\n\\hline\n\\end{array}\n\\]\n\n\nEjemplo 2.23 Utilizando los datos de la muestra de estaturas de estudiantes, la clase con la mayor frecuencia es \\((170,180]\\), que es la clase modal \\(Mo=(170,180]\\).\n\\[\n\\begin{array}{cr}\n\\hline\nX & n_i \\\\\n\\hline\n(150,160] & 2 \\\\\n(160,170] & 8 \\\\\n\\color{red}{(170,180]} & 11 \\\\\n(180,190] & 7 \\\\\n(190,200] & 2 \\\\\n\\hline\n\\end{array}\n\\]\n\n\n\n2.6.4 ¿Qué estadístico de tendencia central usar?\nEn general, siempre que puedan calcularse los estadísticos de tendencia central, es recomendable utilizarlos como valores representativos en el siguiente orden:\n\nMedia. La media utiliza más información que el resto ya que para calcularla se tiene en cuenta la magnitud de los datos.\nMediana. La mediana utiliza menos información que la media, pero más que la moda, ya que para calcularla se tiene en cuenta el orden de los datos.\nModa. La moda es la que menos información utiliza ya que para calcularla sólo se tienen en cuenta las frecuencias absolutas.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nHay que tener cuidado con los datos atípicos, ya que la media puede distorsionarse cuando hay datos atípicos. En tal caso es mejor utilizar la mediana como valor más representativo.\n\n\n\nEjemplo 2.24 Si una muestra de número de hijos de 7 familias es\n\n0, 0, 1, 1, 2, 2, 15,\n\nentonces, \\(\\bar{x}=3\\) hijos y \\(Me=1\\) hijo.\n¿Qué medida representa mejor el número de hijos en la muestra?\n\n\n\n2.6.5 Medidas de posición no centrales\nLas medidas de posición no centrales o cuantiles dividen la distribución en partes iguales.\nLos más utilizados son:\nCuartiles: Dividen la distribución en 4 partes iguales. Hay 3 cuartiles: \\(C_1\\) (25% acumulado), \\(C_2\\) (50% acumulado), \\(C_3\\) (75% acumulado).\nDeciles: Dividen la distribución en 10 partes iguales. Hay 9 deciles: \\(D_1\\) (10% acumulado),…, \\(D_9\\) (90% acumulado).\nPercentiles: Dividen la distribución en 100 partes iguales. Hay 99 percentiles: \\(P_1\\) (1% acumulado),…, \\(P_{99}\\) (99% acumulado).\n\n\n\nCuartiles, deciles y percentiles.\n\n\nObsérvese que hay una correspondencia entre los cuartiles, los deciles y los percentiles. Por ejemplo, el primer cuartil coincide con el percentil 25, y el cuarto decil coincide con el percentil 40.\nLos cuantiles se calculan de forma similar a la mediana. La única diferencia es la frecuencia relativa acumulada que corresponde a cada cuantil.\n\n\n\nCálculo de cuartiles, deciles y percentiles.\n\n\n\nEjemplo 2.25 Utilizando los datos de la muestra del número de hijos de las familias, la frecuencia relativa acumulada era\n\\[\n\\begin{array}{rr}\n\\hline\nx_i & F_i \\\\\n\\hline\n0 & 0.08\\\\\n1 & 0.32\\\\\n2 & 0.88\\\\\n3 & 0.96\\\\\n4 & 1\\\\\n\\hline\n\\end{array}\n\\]\n\\[\\begin{align*}\nF_{C_1}=0.25 &\\Rightarrow Q_1 = 1 \\text{ hijos},\\\\\nF_{C_2}=0.5 &\\Rightarrow Q_2 = 2 \\text{ hijos},\\\\\nF_{C_3}=0.75 &\\Rightarrow Q_3 = 2 \\text{ hijos},\\\\\nF_{D_4}=0.4 &\\Rightarrow D_4 = 2 \\text{ hijos},\\\\\nF_{P_{92}}=0.92 &\\Rightarrow P_{92} = 3 \\text{ hijos}.\n\\end{align*}\\]"
  },
  {
    "objectID": "02-estadistica-descriptiva.html#estadísticos-de-dispersión",
    "href": "02-estadistica-descriptiva.html#estadísticos-de-dispersión",
    "title": "2  Estadística Descriptiva",
    "section": "2.7 Estadísticos de dispersión",
    "text": "2.7 Estadísticos de dispersión\nLa dispersión se refiere a la heterogeneidad o variabilidad de los datos. Así pues, los estadísticos de dispersión mide la variabilidad global de los datos, o con respecto a una medida de tendencia central.\nPara las variables cuantitativas, las más empleadas son:\n\nRecorrido.\nRango Intercuartílico.\nVarianza.\nDesviación Típica.\nCoeficiente de Variación.\n\n\n2.7.1 Recorrido\n\nDefinición 2.6 (Recorrido muestral \\(Re\\)) El recorrido muestral o rango muestral de una variable \\(X\\) se define como la diferencia entre el máximo y el mínimo de los valores en la muestra.\n\\[Re = \\max_{x_i} -\\min_{x_i}\\]\n\n\n\n\nRango muestral.\n\n\nEl recorrido mide la máxima variación que hay entre los datos muestrales. No obstante, es muy sensible a datos atípicos ya que suelen aparecer justo en los extremos de la distribución, por lo que no se suele utilizar mucho.\n\n\n2.7.2 Rango intercuartílico\nPara evitar el problema de los datos atípicos en el recorrido, se puede utilizar el primer y tercer cuartil en lugar del mínimo y el máximo.\n\nDefinición 2.7 (Rango intercuartílico muestral \\(RI\\)) El rango intercuartílico muestral de una variable \\(X\\) se define como la diferencia entre el tercer y el primer cuartil de la muestra.\n\\[RI = C_3 -C_1\\]\n\n\n\n\nRango intercuartílico.\n\n\nEl rango intercuartílico mide la dispersión del 50% de los datos centrales.\n\n\n2.7.3 Diagrama de caja y bigotes\nLa dispersión de una variable suele representarse gráficamente mediante un diagrama de caja y bigotes, que representa cinco estadísticos descriptivos (mínimo, cuartiles y máximo) conocidos como los cinco números. Consiste en una caja, dibujada desde el primer al tercer cuartil, que representa el rango intercuartílico, y dos segmentos, conocidos como bigotes inferior y superior. A menudo la caja se divide en dos por la mediana.\nEste diagrama es muy útil y se utiliza para muchos propósitos:\n\nSirve para medir la dispersión de los datos ya que representa el rango y el rango intercuartílico.\nSirve para detectar datos atípicos, que son los valores que quedan fuera del intervalo definido por los bigotes.\nSirve para medir la simetría de la distribución, comparando la longitud de las cajas y de los bigotes por encima y por debajo de la mediana.\n\n:::{#exm-diagrama-caja} El diagrama siguiente muestra el diagrama de caja y bigotes del peso de una muestra de recién nacidos.\n\n\n\nDiagrama de caja y bigotes del peso de recién nacidos.\n\n\nPara construir el diagrama de caja y bigotes hay que seguir los siguientes pasos:\n\nCalcular los cuartiles.\nDibujar una caja de manera que el extremo inferior caiga sobre el primer cuartil y el extremo superior sobre el tercer cuartil.\nDividir la caja con una línea que caiga sobre el segundo cuartil.\nPara los bigotes inicialmente se calculan dos valores llamados vallas \\(v_1\\) y \\(v_2\\). La valla inferior es el primer cuartil menos una vez y media el rango intercuartílico, y la valla superior es el tercer cuartil más una vez y media el rango intercuartílico.\n\\[\n\\begin{aligned}\nv_1&=Q_1-1.5\\,\\text{IQR}\\\\\nv_2&=Q_3+1.5\\,\\text{IQR}\n\\end{aligned}\n\\]\nLas vallas definen el intervalo donde los datos se consideran normales. Cualquier valor fuera de ese intervalo se considera un dato atípico.\nEl bigote superior se dibuja desde el borde inferior de la caja hasta el menor valor de la muestra que es mayor o igual a la valla inferior, y el bigote superior se dibuja desde el borde superior de la caja hasta el mayor valor de la muestra que es menor o igual a la valla superior.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos bigotes no son las vallas.\n\n\n\nFinalmente, si en la muestra hay algún dato atípico, se dibuja un punto para cada uno de ellos.\n\n\nEjemplo 2.26 El diagrama de caja y bigotes de la muestra del número de hijos de las familias se muestra a continuación.\n\n\n\nDiagrama de caja y bigotes del número de hijos.\n\n\n\n\n2.7.3.1 Desviaciones respecto de la media\nOtra forma de medir la variabilidad de una variable es estudiar la concentración de los valores en torno a algún estadístico de tendencia central como por ejemplo la media.\nPara ello se suele medir la distancia de cada valor a la media. A ese valor se le llama desviación de la media.\n\n\n\nDesviaciones con respecto a la media.\n\n\nSi las desviaciones son grandes la media no será tan representativa como cuando la desviaciones sean pequeñas.\n\nEjemplo 2.27 La siguiente tabla contiene las notas de 3 estudiantes en un curso con las asignaturas \\(A\\), \\(B\\) y \\(C\\).\n\\[\n\\begin{array}{cccc}\n\\hline\nA & B & C & \\bar x \\\\\n0 & 5 & 10 & 5 \\\\\n4 & 5 & 6 & 5 \\\\\n5 & 5 & 5 & 5 \\\\\n\\hline\n\\end{array}\n\\]\nTodos los estudiantes tienen la misma media, pero, en qué caso la media representa mejor el rendimiento en el curso?\n\n\n\n\n2.7.4 Varianza y desviación típica\n\nDefinición 2.8 (Varianza \\(s^2\\)) La varianza muestral de una variable \\(X\\) se define como el promedio del cuadrado de las desviaciones de los valores de la muestra respecto de la media muestral.\n\\[s^2 = \\frac{\\sum (x_i-\\bar x)^2n_i}{n} = \\sum (x_i-\\bar x)^2f_i\\]\n\nTambién puede calcularse de manera más sencilla mediante la fórmula\n\\[s^2 = \\frac{\\sum x_i^2n_i}{n} -\\bar x^2= \\sum x_i^2f_i-\\bar x^2\\]\nLa varianza tiene las unidades de la variable al cuadrado, por lo que para facilitar su interpretación se suele utilizar su raíz cuadrada.\n\nDefinición 2.9 (Desviación típica \\(s\\)) La desviación típica muestral de una variable \\(X\\) se define como la raíz cuadrada positiva de su varianza muestral.\n\\[s = +\\sqrt{s^2}\\]\n\n\n\n\n\n\n\nTip\n\n\n\nTanto la varianza como la desviación típica sirven para cuantificar la dispersión de los datos en torno a la media. Cuando la varianza o la desviación típica son pequeñas, los datos de la muestra están concentrados en torno a la media, y la media es una buena medida de representatividad. Por contra, cuando la varianza o la desviación típica son grandes, los datos de la muestra están alejados de la media, y la media ya no representa tan bien.\n\n\n\nDesviación típica pequeña\n\\(\\Rightarrow\\)\nMedia representativa\n\n\nDesviación típica grande\n\\(\\Rightarrow\\)\nMedia no representativa\n\n\n\n\n\n\nEjemplo 2.28 Las siguientes muestras contienen las notas de dos estudiantes en dos asignaturas.\n\n\n\nInterpretación de la desviación típica.\n\n\n¿Qué media es más representativa?\n\n\nEjemplo 2.29 (Datos no agrupados) Utilizando los datos de la muestra del número de hijos de las familias, con una media \\(\\bar x=1.76\\) hijos, y añadiendo una nueva columna a la tabla de frecuencias con los cuadrados de los valores,\n\\[\n\\begin{array}{rrr}\n\\hline\nx_i & n_i & x_i^2n_i \\\\\n\\hline\n0 & 2 & 0 \\\\\n1 & 6 & 6 \\\\\n2 & 14 & 56\\\\\n3 & 2  & 18\\\\\n4 & 1 & 16 \\\\\n\\hline\n\\sum & 25 & 96 \\\\\n\\hline\n\\end{array}\\]\n\\[s^2 = \\frac{\\sum x_i^2n_i}{n}-\\bar x^2 = \\frac{96}{25}-1.76^2= 0.7424 \\mbox{ hijos}^2.\\]\ny la desviación típica es \\(s=\\sqrt{0.7424} = 0.8616\\) hijos.\nComparado este valor con el recorrido, que va de 0 a 4 hijos se observa que no es demasiado grande por lo que se puede concluir que no hay mucha dispersión y en consecuencia la media de \\(1.76\\) hijos representa bien el número de hijos de las familias de la muestra.\n\n\nEjemplo 2.30 (Datos agrupados) Utilizando los datos de la muestra de estaturas de los estudiantes y agrupando las estaturas en clases, se obtenía una media \\(\\bar x = 174.67\\) cm. El cálculo de la varianza se realiza igual que antes pero tomando como valores de la variable las marcas de clase.\n\\[\n\\begin{array}{crrr}\n\\hline\nX & x_i & n_i & x_i^2n_i \\\\\n\\hline\n(150,160] & 155 & 2 & 48050\\\\\n(160,170] & 165 & 8 & 217800\\\\\n(170,180] & 175 & 11 & 336875\\\\\n(180,190] & 185 & 7 & 239575\\\\\n(190,200] & 195 & 2 & 76050\\\\\n\\hline\n\\sum &  & 30 & 918350 \\\\\n\\hline\n\\end{array}\n\\]\n\\[s^2 = \\frac{\\sum x_i^2n_i}{n}-\\bar x^2 = \\frac{918350}{30}-174.67^2= 102.06 \\mbox{ cm}^2,\\]\ny la desviación típica es \\(s=\\sqrt{102.06} = 10.1\\) cm.\nEste valor es bastante pequeño, comparado con el recorrido de la variable, que va de 150 a 200 cm, por lo que la variable tiene poca dispersión y en consecuencia su media es muy representativa.\n\n\n\n2.7.5 Coeficiente de variación\nTanto la varianza como la desviación típica tienen unidades y eso dificulta a veces su interpretación, especialmente cuando se compara la dispersión de variables con diferentes unidades.\nPor este motivo, es también común utilizar la siguiente medida de dispersión que no tiene unidades.\n\nDefinición 2.10 (Coeficiente de variación muestral \\(cv\\)) El coeficiente de variación muestral de una variable \\(X\\) se define como el cociente entre su desviación típica muestral y el valor absoluto de su media muestral.\n\\[cv = \\frac{s}{|\\bar x|}\\]\n\n\n\n\n\n\n\nTip\n\n\n\nEl coeficiente de variación muestral mide la dispersión relativa de los valores de la muestra en torno a la media muestral.\nComo no tiene unidades, es muy sencillo de interpretar: Cuanto mayor sea, mayor será la dispersión relativa con respecto a la media y menos representativa será la media.\n\n\nEl coeficiente de variación es muy útil para comparar la dispersión de distribuciones de variables diferentes, incluso si las variables tienen unidades diferentes.\n\nEjemplo 2.31 En la muestra del número de hijos, donde la media era \\(\\bar x=1.76\\) hijos y la desviación típica \\(s=0.8616\\) hijos, el coeficiente de variación vale\n\\[cv = \\frac{s}{|\\bar x|} = \\frac{0.8616}{|1.76|} = 0.49.\\]\nEn la muestra de las estaturas, donde la media era \\(\\bar x=174.67\\) cm y la desviación típica \\(s=10.1\\) cm, el coeficiente de variación vale\n\\[cv = \\frac{s}{|\\bar x|} = \\frac{10.1}{|174.67|} = 0.06.\\]\nEsto significa que la dispersión relativa en la muestra de estaturas es mucho menor que en la del número de hijos, por lo que la media de las estaturas será más representativa que la media del número de hijos."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#estadísticos-de-forma",
    "href": "02-estadistica-descriptiva.html#estadísticos-de-forma",
    "title": "2  Estadística Descriptiva",
    "section": "2.8 Estadísticos de forma",
    "text": "2.8 Estadísticos de forma\nSon medidas que describen la forma de la distribución.\nLos aspectos más relevantes son:\nSimetría Mide la simetría de la distribución de frecuencias en torno a la media. El estadístico más utilizado es el Coeficiente de Asimetría de Fisher.\nApuntamiento Mide el apuntamiento o el grado de concentración de valores en torno a la media de la distribución de frecuencias. El estadístico más utilizado es el Coeficiente de Apuntamiento o Curtosis.\n\n2.8.1 Coeficiente de asimetría\n\nDefinición 2.11 (Coeficiente de asimetría muestral \\(g_1\\)) El coeficiente de asimetría muestral de una variable \\(X\\) es el promedio de las desviaciones de los valores de la muestra respecto de la media muestral, elevadas al cubo, dividido por la desviación típica al cubo.\n\\[g_1 = \\frac{\\sum (x_i-\\bar x)^3 n_i/n}{s^3} = \\frac{\\sum (x_i-\\bar x)^3 f_i}{s^3}\\]\n\n\n\n\n\n\n\nTip\n\n\n\nMide el grado de simetría de los valores de la muestra con respecto a la media muestra, es decir, cuantos valores de la muestra están por encima o por debajo de la media y cómo de alejados de esta.\n\n\\(g_1=0\\) indica que hay el mismo número de valores por encima y por debajo de la media e igualmente alejados de ella (simétrica).\n\n\n\n\nDistribución simétrica.\n\n\n\n\\(g_1&lt;0\\) indica que la mayoría de los valores son mayores que la media, pero los valores menores están más alejados de ella (asimétrica a la izquierda).\n\n\n\n\nDistribución asimétrica hacia la izquierda.\n\n\n\n\\(g_1&gt;0\\) indica que la mayoría de los valores son menores que la media, pero los valores mayores están más alejados de ella (asimétrica a la derecha).\n\n\n\n\nDistribución asimétrica hacia la derecha.\n\n\n\n\n\nEjemplo 2.32 (Datos agrupados) Utilizando la tabla de frecuencias de la muestra de estaturas y añadiendo una nueva columna con las desviaciones de la media \\(\\bar x = 174.67\\) cm al cubo, se tiene\n\\[\n\\begin{array}{crrrr}\n\\hline\nX & x_i & n_i & x_i-\\bar x & (x_i-\\bar x)^3 n_i \\\\\n\\hline\n(150,160] & 155 & 2 & -19.67 & -15221.00\\\\\n(160,170] & 165 & 8 & -9.67 & -7233.85\\\\\n(170,180] & 175 & 11 & 0.33 & 0.40\\\\\n(180,190] & 185 & 7 & 10.33 & 7716.12\\\\\n(190,200] & 195 & 2 & 20.33 & 16805.14\\\\\n\\hline\n\\sum &  & 30 & & 2066.81 \\\\\n\\hline\n\\end{array}\n\\]\n\\[g_1 = \\frac{\\sum (x_i-\\bar x)^3n_i/n}{s^3} = \\frac{2066.81/30}{10.1^3} = 0.07.\\]\nComo está cerca de 0, eso significa que la distribución de las estaturas es casi simétrica.\n\n\n\n2.8.2 Coeficiente de apuntamiento o curtosis\n\nDefinición 2.12 (Coeficiente de apuntamiento muestral \\(g_2\\)) El coeficiente de apuntamiento muestral de una variable \\(X\\) es el promedio de las desviaciones de los valores de la muestra respecto de la media muestral, elevadas a la cuarta, dividido por la desviación típica a la cuarta y al resultado se le resta 3.\n\\[g_2 = \\frac{\\sum (x_i-\\bar x)^4 n_i/n}{s^4}-3 = \\frac{\\sum (x_i-\\bar x)^4 f_i}{s^4}-3\\]\n\n\n\n\n\n\n\nTip\n\n\n\nEl coeficiente de apuntamiento mide la concentración de valores en torno a la media y la longitud de las colas de la distribución. Se toma como referencia la distribución normal (campana de Gauss).\n\n\\(g_2=0\\) indica que la distribución tienen un apuntamiento normal, es decir, la concentración de valores en torno a la media es similar al de una campana de Gauss (mesocúrtica).\n\n\n\n\nDistribución mesocúrtica.\n\n\n\n\\(g_2&lt;0\\) indica que la distribución tiene menos apuntamiento de lo normal, es decir, la concentración de valores en torno a la media es menor que en una campana de Gauss (platicúrtica).\n\n\n\n\nDistribución platicúrtica.\n\n\n\n\\(g_2&gt;0\\) indica que la distribución tiene más apuntamiento de lo normal, es decir, la concentración de valores en torno a la media es menor que en una campana de Gauss (leptocúrtica).\n\n\n\n\nDistribución leptocúrtica.\n\n\n\n\n:::{#exm-coeficiente-apuntamiento} ## Datos agrupados Utilizando la tabla de frecuencias de la muestra de estaturas y añadiendo una nueva columna con las desviaciones de la media \\(\\bar x = 174.67\\) cm a la cuarta, se tiene\n\\[\n\\begin{array}{rrrrr}\n\\hline\nX & x_i & n_i & x_i-\\bar x & (x_i-\\bar x)^4 n_i\\\\\n\\hline\n(150,160] & 155 & 2 & -19.67 & 299396.99\\\\\n(160,170] & 165 & 8 & -9.67 & 69951.31\\\\\n(170,180] & 175 & 11 & 0.33 & 0.13\\\\\n(180,190] & 185 & 7 & 10.33 & 79707.53\\\\\n(190,200] & 195 & 2 & 20.33 & 341648.49\\\\\n\\hline\n\\sum &  & 30 & & 790704.45 \\\\\n\\hline\n\\end{array}\n\\]\n\\[g_2 = \\frac{\\sum (x_i-\\bar x)^4n_i/n}{s^4} - 3 = \\frac{790704.45/30}{10.1^4}-3 = -0.47.\\]\nComo se trata de un valor negativo, aunque cercano a 0, podemos decir que la distribución es ligeramente platicúrtica.\nComo se verá más adelante en la parte de inferencia, muchas de las pruebas estadísticas solo pueden aplicarse a poblaciones normales.\nLas poblaciones normales se caracterizan por ser simétricas y mesocúrticas, de manera que, tanto el coeficiente de asimetría como el de apuntamiento pueden utilizarse para contrastar si los datos de la muestra provienen de una población normal.\n\n\n\n\n\n\nTip\n\n\n\nEn general, se suele rechazar la hipótesis de normalidad de la población cuando \\(g_1\\) o \\(g_2\\) estén fuera del intervalo \\([-2,2]\\).\n\n\nEn tal caso, lo habitual es aplicar alguna transformación a la variable para corregir la anormalidad.\n\n\n2.8.3 Distribuciones no normales\n\n2.8.3.1 Distribución asimétrica a la derecha no normal\nUn ejemplo de distribución asimétrica a la derecha es el ingreso de las familias.\n\n\n\nDistribucion de los ingresos familiares de EEUU.\n\n\n\n\n2.8.3.2 Distribución asimétrica a la izquierda no normal\nUn ejemplo de distribución asimétrica a la izquierda es la edad de fallecimiento.\n\n\n\nDistribucion de la edad de fallecimiento.\n\n\n\n\n2.8.3.3 Distribución bimodal no normal\nUn ejemplo de distribución bimodal es la hora de llegada de los clientes de un restaurante.\n\n\n\nDistribucion de la hora de llegada de los clientes de un restaurante."
  },
  {
    "objectID": "02-estadistica-descriptiva.html#transformaciones-de-variables",
    "href": "02-estadistica-descriptiva.html#transformaciones-de-variables",
    "title": "2  Estadística Descriptiva",
    "section": "2.9 Transformaciones de variables",
    "text": "2.9 Transformaciones de variables\nEn muchas ocasiones se suelen transformar los datos brutos para corregir alguna anormalidad de la distribución o simplemente para trabajar con unas unidades más cómodas.\nPor ejemplo, si estamos trabajando con estaturas medidas en metros y tenemos los siguientes valores:\n\\[\n1.75 \\mbox{ m}, 1.65 \\mbox{ m}, 1.80 \\mbox{ m},\n\\]\npodemos evitar los decimales multiplicando por 100, es decir, pasando de metros a centímetros:\n\\[\n175 \\mbox{ cm}, 165 \\mbox{ cm}, 180 \\mbox{ cm},\n\\]\nY si queremos reducir la magnitud de los datos podemos restarles a todos el menor de ellos, en este caso, 165cm:\n\\[10\\mbox{cm}, 0\\mbox{cm}, 15\\mbox{cm},\\]\nEstá claro que este conjunto de datos es mucho más sencillo que el original. En el fondo lo que se ha hecho es aplicar a los datos la transformación:\n\\[Y= 100X-165\\]\n\n2.9.1 Transformaciones lineales\nUna de las transformaciones más habituales es la transformación lineal:\n\\[Y=a+bX.\\]\n\nTeorema 2.1 Dada una variable muestral \\(X\\), si \\(Y\\) es la variable muestral que resulta de aplicar a \\(X\\) la transformación lineal \\(Y=a+bX\\), entonces\n\\[\\begin{align*}\n\\bar y &= a+ b\\bar x,\\\\\ns_{y} &= |b|s_{x}\n\\end{align*}\\]\nAdemás, el coeficiente de curtosis no se altera y el de asimetría sólo cambia de signo si \\(b\\) es negativo.\n\n\n\n\n\n\n\nDemostración\n\n\n\n\n\nSe deja como ejercicio. \n\n\n\n\n\n2.9.2 Transformación de tipificación y puntuaciones típicas\nUna de las transformaciones lineales más habituales es la tipificación:\n\nDefinición 2.13 (Variable tipificada) La variable tipificada de una variable estadística \\(X\\) es la variable que resulta de restarle su media y dividir por su desviación típica.\n\\[Z=\\frac{X-\\bar x}{s_{x}}\\]\nPara cada valor \\(x_i\\) de la muestra, la puntuación típica es el valor que resulta de aplicarle la transformación de tipificación\n\\[z_i=\\frac{x_i-\\bar x}{s_{x}}.\\]\n\n\n\n\n\n\n\nTip\n\n\n\nLa puntuación típica es el número de desviaciones típicas que un valor está por encima o por debajo de la media, y es útil para evitar la dependencia de una variable respecto de las unidades de medida empleadas. Esto es útil, por ejemplo, para comparar valores de variables o muestras distintas.\n\n\n\nDada una variable muetral \\(X\\), si \\(Z\\) es la variable tipificada de \\(X\\), entonces\n\\[\\bar z = 0 \\qquad s_{z} = 1.\\]\n\n\n\n\n\n\n\nDemostración\n\n\n\n\n\nSe deja como ejercicio. \n\n\n\n\nEjemplo 2.33 Las notas de 5 alumnos en dos asignaturas \\(X\\) e \\(Y\\) son\n\\[\n\\begin{array}{rccccccccc}\n\\mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\\\\n\\hline\nX: & 2 & 5 & 4 & \\color{red} 8 & 6 & \\qquad & \\bar x = 5 & \\quad s_x = 2\\\\\nY: & 1 & 9 & \\color{red} 8 & 5 & 2 & \\qquad & \\bar y = 5 & \\quad s_y = 3.16\\\\\n\\hline\n\\end{array}\n\\]\n¿Ha tenido el mismo rendimiento el cuarto alumno en la asignatura \\(X\\) que el tercero en la asignatura \\(Y\\)?\nPodría parecer que ambos alumnos han tenido el mismo rendimiento puesto que tienen la misma nota, pero si queremos ver el rendimiento relativo al resto del grupo, tendríamos que tener en cuenta la dispersión de cada muestra y medir sus puntuaciones típicas:\n\\[\n\\begin{array}{cccccc}\n\\mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\\\\n\\hline\nX: & -1.50 & 0.00 & -0.50 & \\color{red}{1.50} & 0.50 \\\\\nY: & -1.26 & 1.26 & \\color{red}{0.95} & 0.00 & -0.95\\\\\n\\hline\n\\end{array}\n\\]\nEs decir, el alumno que tiene un 8 en \\(X\\) está \\(1.5\\) veces la desviación típica por encima de la media de \\(X\\), mientras que el alumno que tiene un 8 en \\(Y\\) sólo está \\(0.95\\) desviaciones típicas por encima de la media de \\(Y\\). Así pues, el primer alumno tuvo un rendimiento superior al segundo.\nSiguiendo con el ejemplo anterior y considerando ambas asignaturas, ¿cuál es el mejor alumno?\nSi simplemente se suman las puntuaciones de cada asignatura se tiene:\n\\[\\begin{array}{rccccc}\n\\mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\\\\n\\hline\nX: & 2 & 5 & 4 & 8 & 6 \\\\\nY: & 1 & 9 & 8 & 5 & 2 \\\\\n\\hline\n\\sum & 3 & \\color{red}{14} & 12 & 13 & 8\n\\end{array}\n\\]\nEl mejor alumno sería el segundo.\nPero si se considera el rendimiento relativo tomando las puntuaciones típicas se tiene\n\\[\n\\begin{array}{rccccc}\n\\mbox{Alumno:} & 1 & 2 & 3 & 4 & 5\\\\\n\\hline\nX: & -1.50 & 0.00 & -0.50 & 1.50 & 0.50 \\\\\nY: & -1.26 & 1.26 & 0.95 & 0.00 & -0.95\\\\\n\\hline\n\\sum & -2.76 & 1.26 & 0.45 & \\color{red}{1.5} & -0.45\n\\end{array}\n\\]\nY el mejor alumno sería el cuarto.\n\n\n2.9.2.1 Transformaciones no lineales\nLas transformaciones no lineales son también habituales para corregir la anormalidad de las distribuciones.\nLa transformación \\(Y=X^2\\) comprime la escala para valores pequeños y la expande para valores altos, de manera que es muy útil para corregir asimetrías hacia la izquierda.\n\n\n\nTransformación cuadrática.\n\n\nLas transformaciones \\(Y=\\sqrt x\\), \\(Y= \\log X\\) y \\(Y=1/X\\) comprimen la escala para valores altos y la expanden para valores pequeños, de manera que son útiles para corregir asimetrías hacia la derecha.\n\n\n\nTransformación logarítmica.\n\n\n\n\n\n2.9.3 Variables clasificadoras o factores\nEn ocasiones interesa describir el comportamiento de una variable, no para toda la muestra, sino para distintos grupos de individuos correspondientes a las categorías de otra variable conocida como variable clasificadora o factor.\n\nEjemplo 2.34 Dividiendo la muestra de estaturas según el sexo se obtienen dos submuestras:\n\\[\n\\begin{array}{lll}\n\\hline\n\\mbox{Mujeres} & & 173, 158, 174, 166, 162, 177, 165, 154, 166, 182, 169, 172, 170, 168. \\\\\n\\mbox{Hombres} & & 179, 181, 172, 194, 185, 187, 198, 178, 188, 171, 175, 167, 186, 172, 176, 187. \\\\\n\\hline\n\\end{array}\n\\]\n\nHabitualmente los factores se usan para comparar la distribución de la variable principal para cada categoría del factor.\n\nEjemplo 2.35 Los siguientes diagramas permiten comparar la distribución de estaturas según el sexo.\n\n\n\nHistograma de estaturas por sexo.\n\n\n\n\n\nDiagramas de cajas de estaturas por sexo."
  },
  {
    "objectID": "07-estimacion.html#estimación-de-parámetros",
    "href": "07-estimacion.html#estimación-de-parámetros",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.1 Estimación de Parámetros",
    "text": "3.1 Estimación de Parámetros\nLos modelos de distribución de probabilidad vistos en el tema anterior explican el comportamiento de las variables aleatorias, pero para ello debemos saber qué modelo de distribución sigue una determinada variable. Este es el primer paso de la etapa de Inferencia Estadística.\nPara determinar con exactitud el modelo de distribución de una variable hay que conocer la característica estudiada en todos los individuos de la población, lo cual no es posible en la mayoría de los casos (inviabilidad económica, física, temporal, etc.).\nPara evitar estos inconvenientes se recurre al estudio de una muestra, a partir de la cual se trata de averiguar, de manera aproximada, el modelo de distribución de la variable en la población.\nEstudiar un número reducido de individuos de una muestra en lugar de toda la población tiene indudables ventajas:\n\nMenor coste.\nMayor rapidez.\nMayor facilidad.\n\nPero también presenta algunos inconvenientes:\n\nNecesidad de conseguir una muestra representativa.\nPosibilidad de cometer errores (sesgos).\n\nAfortunadamente, estos errores pueden ser superados: La representatividad de la muestra se consigue eligiendo la modalidad de muestreo más apropiada para el tipo de estudio; en el caso de los errores, aunque no se pueden evitar, se tratará de reducirlos al máximo y acotarlos."
  },
  {
    "objectID": "07-estimacion.html#distribuciones-muestrales",
    "href": "07-estimacion.html#distribuciones-muestrales",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.2 Distribuciones muestrales",
    "text": "3.2 Distribuciones muestrales\nLos valores de una variable \\(X\\) en una muestra de tamaño \\(n\\) de una población pueden verse como el valor de una variable aleatoria \\(n\\)-dimensional.\n\nDefinición 3.1 (Variable aleatoria muestral) Una variable aleatoria muestral de una variable \\(X\\) estudiada en una población es una colección de \\(n\\) variables aleatorias \\(X_1,\\ldots,X_n\\) tales que:\n\nCada una de las variables \\(X_i\\) sigue la misma distribución de probabilidad que la variable \\(X\\) en la población.\nTodas las variables \\(X_i\\) son mutuamente independientes.\n\n\nLos valores que puede tomar esta variable \\(n\\) dimensional, serán todas las posibles muestras de tamaño \\(n\\) que pueden extraerse de la población.\n\n\n\nProceso de obtención de la muestra.\n\n\nLas tres características fundamentales de la variable aleatoria muestral son:\n\nHomogeneidad: Las \\(n\\) variables que componen la variable aleatoria muestral siguen la misma distribución.\nIndependencia: Las variables son independientes entre sí.\nModelo de distribución: El modelo de distribución que siguen las \\(n\\) variables.\n\nLas dos primeras cuestiones pueden resolverse si se utiliza muestreo aleatorio simple para obtener la muestra. En cuanto a la última, hay que responder, a su vez, a dos cuestiones:\n\n¿Qué modelo de distribución se ajusta mejor a nuestro conjunto de datos? Esto se resolverá, en parte, mediante la utilización de técnicas no paramétricas.\nUna vez seleccionado el modelo de distribución más apropiado, ¿qué estadístico del modelo nos interesa y cómo determinar su valor? De esto último se encarga la parte de la inferencia estadística conocida como Estimación de Parámetros.\n\nEn este tema se abordará la segunda cuestión, es decir, suponiendo que se conoce el modelo de distribución de una población, se intentará estimar los principales parámetros que la definen. Por ejemplo, los principales parámetros que definen las distribuciones vistas en el tema anterior son:\n\n\n\nDistribución\nParámetro\n\n\n\n\nBinomial\n\\(n,p\\)\n\n\nPoisson\n\\(\\lambda\\)\n\n\nUniforme\n\\(a,b\\)\n\n\nNormal\n\\(\\mu,\\sigma\\)\n\n\nChi-cuadrado\n\\(n\\)\n\n\nT-Student\n\\(n\\)\n\n\nF-Fisher\n\\(m,n\\)\n\n\n\nLa distribución de probabilidad de los valores de la variable muestral depende claramente de la distribución de probabilidad de los valores de la población.\n\nEjemplo 3.1 Sea una población en la que la cuarta parte de las familias no tienen hijos, la mitad de las familias tiene 1 hijo, y el resto tiene 2 hijos.\n\n\n\n\n\n\nPor ser función de una variable aleatoria, un estadístico en el muestreo es también una variable aleatoria. Por tanto, su distribución de probabilidad también depende de la distribución de la población y de los parámetros que la determinan (\\(\\mu\\), \\(\\sigma\\), \\(p\\), …).\n\nEjemplo 3.2 Si se toma la media muestral \\(\\bar X\\) de las muestras de tamaño 2 del ejemplo anterior, su distribución de probabilidad es\n\n\n\n\n\n\n::: {.content-visible when-format=“html”} :::{layout-ncol=“2”} \n :::\n¿Cuál es la probabilidad de obtener una media muestral que aproxime la media poblacional con un error máximo de 0.5?\nComo hemos visto, para conocer la distribución de un estadístico muestral, es necesario conocer la distribución de la población, lo cual no siempre es posible. Afortunadamente, para muestras grandes es posible aproximar la distribución de algunos estadísticos como la media, gracias al siguiente teorema:\n\nTeorema 3.1 (Teorema central del límite) Si \\(X_1,\\ldots, X_n\\) son variables aleatorias independientes (\\(n\\geq 30\\)) con medias y varianzas \\(\\mu_i=E(X_i)\\), \\(\\sigma^2_i=Var(X_i)\\), \\(i=1,\\ldots,n\\) respectivamente, entonces la variable aleatoria \\(X=X_1+\\cdots+X_n\\) sigue una distribución aproximadamente normal de media la suma de las medias y varianza la suma de las varianzas\n\\[\nX=X_1+\\cdots+X_n\\stackrel{n\\geq 30} \\sim N\\left(\\sum_{i=1}^n \\mu_i, \\sqrt{\\sum_{i=1}^n \\sigma^2_i}\\right)\n\\]\n\nEste teorema además es la explicación de que la mayoría de las variables biológicas presenten una distribución normal, ya que suelen ser causa de múltiples factores que suman sus efectos de manera independiente.\n\n3.2.1 Distribución de la media muestral para muestras grandes (\\(n\\geq 30\\))\nLa media muestral de una muestra aleatoria de tamaño \\(n\\) es la suma de \\(n\\) variables aleatorias independientes, idénticamente distribuidas:\n\\[\n\\bar X = \\frac{X_1+\\cdots+X_n}{n} = \\frac{X_1}{n}+\\cdots+\\frac{X_n}{n}\n\\]\nDe acuerdo a las propiedades de las transformaciones lineales, la media y la varianza de cada una de estas variables son\n\\[\nE\\left(\\frac{X_i}{n}\\right) =\\frac{\\mu}{n} \\quad  \\mbox{y} \\quad Var\\left(\\frac{X_i}{n}\\right) = \\frac{\\sigma^2}{n^2}\n\\]\ncon \\(\\mu\\) y \\(\\sigma^2\\) la media y la varianza de la población de partida.\nEntonces, si el tamaño de la muestra es grande (\\(n\\geq 30\\)), de acuerdo al teorema central del límite, la distribución de la media muestral será normal:\n\\[\n\\bar X \\sim N\\left(\\sum_{i=1}^n \\frac{\\mu}{n},\\sqrt{\\sum_{i=1}^n \\frac{\\sigma^2}{n^2}} \\right) = N\\left(\\mu,\\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nEjemplo 3.3 (Ejemplo para muestras grandes (\\(n\\geq 30\\))) Supóngase que se desea estimar el número medio de hijos de una población con media \\(\\mu=2\\) hijos y desviación típica \\(\\sigma=1\\) hijo.\n¿Qué probabilidad hay de estimar \\(\\mu\\) a partir de \\(\\bar x\\) con un error menor de \\(0.2\\)?\n\n\nDe acuerdo al teorema central del límite se tiene:\n\nPara \\(n=30\\), \\(\\bar x\\sim N(2,1/\\sqrt{30})\\) y\n\n\\[\nP(1.8&lt;\\bar x&lt;2.2) = 0.7267.\n\\]\n\nPara \\(n=100\\), \\(\\bar x\\sim N(2,1/\\sqrt{100})\\) y\n\n\\[\nP(1.8&lt;\\bar x&lt;2.2) = 0.9545.\n\\]\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Distribución de una proporción muestral para muestras grandes (\\(n\\geq 30\\))\nUna proporción \\(p\\) poblacional puede calcularse como la media de una variable dicotómica (0,1). Esta variable se conoce como variable de Bernouilli \\(B(p)\\), que es un caso particular de la binomial para \\(n=1\\). Por tanto, para una muestra aleatoria de tamaño \\(n\\), una proporción muestral \\(\\hat p\\) también puede expresarse como la suma de \\(n\\) variables aleatorias independientes, idénticamente distribuidas:\n\\[\n\\hat p = \\bar X = \\frac{X_1+\\cdots+X_n}{n} = \\frac{X_1}{n}+\\cdots+\\frac{X_n}{n}, \\mbox{ con } X_i\\sim B(p)\n\\]\ny con media y varianza\n\\[\nE\\left(\\frac{X_i}{n}\\right) =\\frac{p}{n} \\quad  \\mbox{y} \\quad Var\\left(\\frac{X_i}{n}\\right) = \\frac{p(1-p)}{n^2}\n\\]\nEntonces, si el tamaño de la muestra es grande (\\(n\\geq 30\\)), de acuerdo al teorema central del límite, la distribución de la proporción muestral también será normal:\n\\[\n\\hat p \\sim N\\left(\\sum_{i=1}^n \\frac{p}{n},\\sqrt{\\sum_{i=1}^n \\frac{p(1-p)}{n^2}} \\right) = N\\left(p,\\sqrt{\\frac{p(1-p)}{n}} \\right).\n\\]"
  },
  {
    "objectID": "07-estimacion.html#estimadores",
    "href": "07-estimacion.html#estimadores",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.3 Estimadores",
    "text": "3.3 Estimadores\nLos estadísticos muestrales pueden utilizarse para aproximar los parámetros de la población, y cuando un estadístico se utiliza con este fin se le llama estimador del parámetro.\n\nDefinición 3.2 (Estimador y estimación) Un estimador es una función de la variable aleatoria muestral\n\\[\n\\hat \\theta = F(X_1,\\ldots,X_n).\n\\]\nDada una muestra concreta \\((x_1,\\ldots,x_n)\\), el valor del estimador aplicado a ella se conoce como estimación\n\\[\n\\hat \\theta_0 = F(x_1,\\ldots,x_n).\n\\]\n\nPor ser una función de la variable aleatoria muestral, un estimador es, a su vez, una variable aleatoria cuya distribución depende de la población de partida.\nMientras que el estimador es una función que es única, la estimación no es única, sino que depende de la muestra tomada.\n\n\n\n\n\n\nEjemplo 3.4 Supóngase que se quiere saber la proporción \\(p\\) de fumadores en una ciudad. En ese caso, la variable dicotómica que mide si una persona fuma (1) o no (0), sigue una distribución de Bernouilli \\(B(p)\\).\nSi se toma una muestra aleatoria de tamaño 5, \\((X_1,X_2,X_3,X_4,X_5)\\), de esta población, se puede utilizar la proporción de fumadores en la muestra como estimador para la proporción de fumadores en la población:\n\\[\n\\hat p = \\frac{\\sum_{i=1}^5 X_i}{5}\n\\]\nEste estimador es una variable que se distribuye \\(\\hat p\\sim \\frac{1}{n}B\\left(p,\\sqrt{\\frac{p(1-p)}{n}}\\right)\\).\nSi se toman distintas muestras, se obtienen diferentes estimaciones:\n\\[\n\\begin{array}{|c|c|}\n\\hline\n\\mbox{Muestra} & \\mbox{Estimación}\\\\\n\\hline\\hline\n(1, 0, 0, 1, 1) & 3/5\\\\\n\\hline\n(1, 0, 0, 0, 0) & 1/5\\\\\n\\hline\n(0, 1, 0, 0, 1) & 2/5\\\\\n\\hline\n\\cdots & \\cdots\\\\\n\\hline\n\\end{array}\n\\]\n\nLa estimación de parámetros puede realizar de de dos formas:\n\nEstimación puntual: Se utiliza un único estimador que proporciona un valor o estimación aproximada del parámetro. El principal inconveniente de este tipo de estimación es que no se especifica la bondad de la estimación.\nEstimación por intervalos: Se utilizan dos estimadores que proporcionan los extremos de un intervalo dentro del cual se cree que está el verdadero valor del parámetro con un cierto grado de seguridad. Esta forma de estimar sí permite controlar el error cometido en la estimación."
  },
  {
    "objectID": "07-estimacion.html#estimación-puntual",
    "href": "07-estimacion.html#estimación-puntual",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.4 Estimación puntual",
    "text": "3.4 Estimación puntual\nLa estimación puntual utiliza un único estimador para estimar el valor del parámetro desconocido de la población.\nEn teoría pueden utilizarse distintos estimadores para estimar un mismo parámetro. Por ejemplo, en el caso de estimar la proporción de fumadores en una ciudad, podrían haberse utilizado otros posibles estimadores además de la proporción muestral, como pueden ser: \\[\\begin{align*}\n\\hat \\theta_1 &= \\sqrt[5]{X_1X_2X_3X_4X_5}\\\\\n\\hat \\theta_2 &= \\frac{X_1+X_5}{2}\\\\\n\\hat \\theta_3 &= X_1 \\cdots\n\\end{align*}\\]\n¿Cuál es el mejor estimador?\nLa respuesta a esta cuestión depende de las propiedades de cada estimador.\nAunque la estimación puntual no proporciona ninguna medida del grado de bondad de la estimación, existen varias propiedades que garantizan dicha bondad.\nLas propiedades más deseables en un estimador son:\n\nInsesgadez\nEficiencia\nConsistencia\nNormalidad asintótica\nSuficiencia\n\n\nDefinición 3.3 (Estimador insesgado) Un estimador \\(\\hat \\theta\\) es insesgado para un parámetro \\(\\theta\\) si su esperanza es precisamente \\(\\theta\\), es decir,\n\\[\nE(\\hat \\theta)=\\theta.\n\\]\n\n\n\n\nDistribución de estimadores sesgados e insesgados.\n\n\nCuando un estimador no es insesgado, a la diferencia entre su esperanza y el valor del parámetro \\(\\theta\\) se le llama sesgo:\n\\[\nSesgo(\\hat \\theta) = E(\\hat \\theta)-\\theta.\n\\]\nCuanto menor sea el sesgo de un estimador, mejor se aproximarán sus estimaciones al verdadero valor del parámetro.\n\nDefinición 3.4 (Estimador consistente) Un estimador \\(\\hat \\theta_n\\) para muestras de tamaño \\(n\\) es consistente para un parámetro \\(\\theta\\) si para cualquier valor \\(\\epsilon&gt;0\\) se cumple\n\\[\n\\lim_{n\\rightarrow \\infty} P(|\\hat \\theta_n-\\theta|&lt;\\epsilon)=1.\n\\]\n\n\n\n\n\n\n\nDistribución de estimadores consistentes.\n\n\n\n\n\n\n\nDistribución de estimadores consistentes segados.\n\n\n\n\n\nLas condiciones suficientes para que un estimador sea consistente son:\n\n\\(Sesgo(\\hat \\theta_n)=0\\) o \\(\\lim_{n\\rightarrow \\infty}Sesgo(\\hat \\theta_n)=0\\).\n\\(\\lim_{n\\rightarrow \\infty}Var(\\hat \\theta_n)=0\\).\n\nAsí pues, si la varianza y el sesgo disminuyen a medida que aumenta el tamaño de la muestra, el estimador será consistente.\n\nDefinición 3.5 (Estimador eficiente) Un estimador \\(\\hat \\theta\\) de un parámetro \\(\\theta\\) es eficiente si tiene el menor error cuadrático medio\n\\[\nECM(\\hat \\theta) = Sesgo(\\hat \\theta)^2+Var(\\theta).\n\\]\n\n\n\n\n\nDistribución de estimadores insesgados y eficientes sesgados.\n\n\n\nDefinición 3.6 (Estimador asintóticamente normal) Un estimador \\(\\hat \\theta\\) es asintóticamente normal si, independientemente de la distribución de la variable aleatoria muestral, su distribución es normal si el tamaño de la muestra es suficientemente grande.:::\n\nComo veremos más adelante esta propiedad es muy interesante para hacer estimaciones de parámetros mediante intervalos.\n\n\n\nDistribución de estimadores asintóticamente normales.\n\n\n\nDefinición 3.7 (Estimador suficiente) Un estimador \\(\\hat \\theta\\) es suficiente para un parámetro \\(\\theta\\), si la distribución condicionada de la variable aleatoria muestral, una vez dada la estimación \\(\\hat \\theta = \\hat \\theta_0\\), no depende de \\(\\theta\\).\n\nEsto significa que cuando se obtiene una estimación, cualquier otra información es irrelevante para \\(\\theta\\).\nEl estimador que se suele utilizar para estimar la media poblacional es la media muestral.\nPara muestras de tamaño \\(n\\) resulta la siguiente variable aleatoria:\n\\[\n\\bar X = \\frac{X_1+\\cdots+X_n}{n}\n\\]\nSi la población de partida tiene media \\(\\mu\\) y varianza \\(\\sigma^2\\) se cumple\n\\[\nE(\\bar X) = \\mu \\quad \\mbox{y} \\quad Var(\\bar X)=\\frac{\\sigma^2}{n}\n\\]\nAsí pues, la media muestral es un estimador insesgado, y como su varianza disminuye a medida que aumenta el tamaño muestral, también es consistente y eficiente.\nSin embargo, la varianza muestral\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (X_i-\\bar X)^2}{n}\n\\]\nes un estimador sesgado para la varianza poblacional, ya que\n\\[\nE(S^2)= \\frac{n-1}{n}\\sigma^2.\n\\]\nNo obstante, resulta sencillo corregir este sesgo para llegar a un estimador insesgado:\n\nDefinición 3.8 (Cuasivarianza muestral) Dada una muestra de tamaño \\(n\\) de una variable aleatoria \\(X\\), se define la cuasivarianza muestral como\n\\[\n\\hat{S}^2 = \\frac{\\sum_{i=1}^n (X_i-\\bar X)^2}{n-1} = \\frac{n}{n-1}S^2.\n\\]"
  },
  {
    "objectID": "07-estimacion.html#estimación-por-intervalos",
    "href": "07-estimacion.html#estimación-por-intervalos",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.5 Estimación por intervalos",
    "text": "3.5 Estimación por intervalos\nEl principal problema de la estimación puntual es que, una vez seleccionada la muestra y hecha la estimación, resulta imposible saber el error cometido.\n\n\n\n\n\nPara controlar el error de la estimación es mejor utilizar la estimación por intervalos\n\n\n\n\n\nLa estimación por intervalos trata de construir a partir de la muestra un intervalo dentro del cual se supone que se encuentra el parámetro a estimar con un cierto grado de confianza. Para ello se utilizan dos estimadores, uno para el límite inferior del intervalo y otro para el superior.\n\nDefinición 3.9 (Intervalo de confianza) Dados dos estimadores \\(\\hat l_i(X_1,\\ldots,X_n)\\) y \\(\\hat l_s(X_1,\\ldots,X_n)\\), y sus respectivas estimaciones \\(l_1\\) y \\(l_2\\) para una muestra concreta, se dice que el intervalo \\(I=[l_1,l_2]\\) es un intervalo de confianza para un parámetro poblacional \\(\\theta\\), con un nivel de confianza \\(1-\\alpha\\) (o nivel de significación \\(\\alpha\\)), si se cumple\n\\[\nP(\\hat l_i(X_1,\\ldots,X_n)\\leq \\theta \\leq \\hat l_s(X_1,\\ldots,X_n))= 1-\\alpha.\n\\]\n\nUn intervalo de confianza nunca garantiza con absoluta certeza que el parámetro se encuentra dentro él.\nTampoco se puede decir que la probabilidad de que el parámetro esté dentro del intervalo es \\(1-\\alpha\\), ya que una vez calculado el intervalo, las variables aleatorias que determinan sus extremos han tomado un valor concreto y ya no tiene sentido hablar de probabilidad, es decir, o el parámetro está dentro, o está fuera, pero con absoluta certeza.\nLo que si se deduce de la definición es que el \\((1-\\alpha)\\%\\) de los intervalos correspondientes a las todas las posibles muestras aleatorias, contendrán al parámetro. Es por eso que se habla de y no de probabilidad.\nPara que un intervalo sea útil su nivel de confianza debe ser alto:\n\\[\\begin{align*}\n1-\\alpha &= 0.90 \\mbox{ o } \\alpha=0.10\\\\\n\\color{red}{1-\\alpha} &= \\color{red}{0.95} \\mbox{ o } \\color{red}{\\alpha=0.05}\\\\\n1-\\alpha &= 0.99 \\mbox{ o } \\alpha=0.01\\\\\n\\end{align*}\\]\nsiendo \\(0.95\\) el nivel de confianza más habitual y \\(0.99\\) en casos críticos.\nTeóricamente, de cada 100 intervalos para estimar un parámetro \\(\\theta\\) con nivel de confianza \\(1-\\alpha=0.95\\), 95 contendrían a \\(\\theta\\) y sólo 5 lo dejarían fuera.\n\n\n\n\n\n\n3.5.1 Error de estimación\nOtro de los aspectos más importantes de un intervalo de confianza es su error.\n\nDefinición 3.10 (Error o imprecisión de un intervalo) El error o la imprecisión de un intervalo de confianza \\([l_i,l_s]\\) es su amplitud\n\\[\nA=l_s-l_i.\n\\]\n\n\n\n\n\n\nPara que un intervalo sea útil no debe ser demasiado impreciso.\nEn general, la precisión de un intervalo depende de tres factores:\n\nLa dispersión de la población. Cuanto más dispersa sea, menos preciso será el intervalo.\nEl nivel de confianza. Cuanto mayor sea el nivel de confianza, menos preciso será el intervalo.\nEl tamaño muestral. Cuanto mayor sea el tamaño muestral, más preciso será el intervalo.\n\n\nSi la confianza y la precisión están reñidas, ¿cómo se puede ganar precisión sin perder confianza?\n\nHabitualmente, para calcular un intervalo de confianza se suele partir de un estimador puntual del que se conoce su distribución muestral.\nA partir de este estimador se calculan los extremos del intervalo sobre su distribución, buscando los valores que dejan encerrada una probabilidad \\(1-\\alpha\\). Estos valores suelen tomarse de manera simétrica, de manera que el extremo inferior deje una probabilidad acumulada inferior \\(\\alpha/2\\) y el extremo superior deje una probabilidad acumulada superior también de \\(\\alpha/2\\)."
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-para-una-población",
    "href": "07-estimacion.html#intervalos-de-confianza-para-una-población",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.6 Intervalos de confianza para una población",
    "text": "3.6 Intervalos de confianza para una población\nA continuación se presentan los intervalos de confianza para estimar un parámetro de una poblacion:\n\nIntervalo para la media de una población normal con varianza conocida.\nIntervalo para la media de una población normal con varianza desconocida.\nIntervalo para la media de una población con varianza desconocida a partir de muestras grandes.\nIntervalo para la varianza de una población normal.\nIntervalo para un proporción de una población.\n\n\n3.6.1 Intervalo de confianza para la media de una población normal con varianza conocida\nSea \\(X\\) una variable aleatoria que cumple las siguientes hipótesis:\n\nSu distribución es normal \\(X\\sim N(\\mu,\\sigma)\\).\nLa media \\(\\mu\\) es desconocida, pero su varianza \\(\\sigma^2\\) es conocida.\n\nBajo estas hipótesis, la media muestral, para muestras de tamaño \\(n\\), sigue también una distribución normal\n\\[\n\\bar X \\sim N\\left(\\mu,\\frac{\\sigma}{\\sqrt n}\\right)\n\\]\nTipificando la variable se tiene\n\\[\nZ=\\frac{\\bar X-\\mu}{\\sigma/\\sqrt n} \\sim N(0,1)\n\\]\nSobre esta distribución resulta sencillo calcular los valores \\(z_i\\) y \\(z_s\\) de manera que\n\\[\nP(z_i\\leq Z \\leq z_s) = 1-\\alpha.\n\\]\nComo la distribución normal estándar es simétrica respecto al 0, lo mejor es tomar valores opuestos \\(-z_{\\alpha/2}\\) y \\(z_{\\alpha/2}\\) que dejen sendas colas de probabilidad acumulada \\(\\alpha/2\\).\n\n\n\n\n\nA partir de aquí, deshaciendo la tipificación, resulta sencillo llegar a los estimadores que darán los extremos del intervalo de confianza:\n\\[\\begin{align*}\n1-\\alpha &= P(-z_{\\alpha/2}\\leq Z \\leq z_{\\alpha/2}) = P\\left(-z_{\\alpha/2}\\leq \\frac{\\bar X -\\mu}{\\sigma/\\sqrt{n}} \\leq z_{\\alpha/2}\\right) =\\\\\n&= P\\left(-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\leq \\bar X -\\mu \\leq z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)=\\\\\n&= P\\left(-\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\leq -\\mu \\leq -\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)= \\\\\n&= P\\left(\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\leq \\mu \\leq \\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right).\n\\end{align*}\\]\nAsí pues, el intervalo de confianza para la media de una población normal con varianza conocida es:\n\nTeorema 3.2 (Intervalo de confianza para la media de una población normal con varianza conocida) Si \\(X\\sim N(\\mu, \\sigma)\\) con \\(\\sigma\\) conocida, el intervalo de confianza para la media \\(\\mu\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}},\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right]\n\\] o bien \\[\n\\bar{X}\\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n\\]\n\nDe la fórmula del intervalo de confianza\n\\[\n\\bar{X}\\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n\\]\nse deducen varias características:\n\nEl intervalo está centrado en la media muestral \\(\\bar X\\) que era el mejor estimador de la media poblacional.\nLa amplitud o imprecisión del intervalo es\n\n\\[\nA= 2 z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n\\]\nde manera que depende de:\n\n\\(\\sigma\\): cuanto mayor sea la varianza poblacional, mayor será la imprecisión.\n\\(z_{\\alpha/2}\\): que a su vez depende del nivel de confianza, y cuanto mayor sea \\(1-\\alpha\\), mayor será la imprecisión.\n\\(n\\): cuanto mayor sea el tamaño de la muestra, menor será la imprecisión.\n\nPor tanto, la única forma de reducir la imprecisión del intervalo, manteniendo la confianza, es aumentando el tamaño muestral.\n\n3.6.1.1 Cálculo del tamaño muestra para estimar la media de una población normal con varianza conocida\nTeniendo en cuenta que la amplitud o imprecisión del intervalo para la media de una población normal con varianza conocida es\n\\[\nA= 2 z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n\\]\nse puede calcular fácilmente el tamaño muestral necesario para conseguir un intervalo de amplitud \\(A\\) con confianza \\(1-\\alpha\\):\n\\[\nA= 2 z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\Leftrightarrow \\sqrt{n}= 2 z_{\\alpha/2}\\frac{\\sigma}{A},\n\\]\nde donde se deduce\n\\[\n\\color{red}{n = 4 z_{\\alpha/2}^2\\frac{\\sigma^2}{A^2}}\n\\]\n\nEjemplo 3.5 Sea una población de estudiantes en la que la puntuación obtenida en un examen sigue una distribución normal \\(X\\sim N(\\mu,\\sigma=1.5)\\).\nPara estimar la nota media \\(\\mu\\), se toma una muestra de 10 estudiantes:\n\\[\n4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3\n\\]\nA partir de esta muestra, podemos calcular el intervalo de confianza para \\(\\mu\\) con un nivel de confianza \\(1-\\alpha=0.95\\) (nivel de significación \\(\\alpha=0.05\\)):\n\n\\(\\bar X = \\frac{4+\\cdots+3}{10}= \\frac{53}{10} = 5.3\\) puntos.\n\\(z_{\\alpha/2}=z_{0.025}\\) es el valor de la normal estándar que deja una probabilidad acumulada superior de \\(0.025\\), que vale aproximadamente \\(1.96\\).\n\nSustituyendo estos valores en la fórmula del intervalo, se tiene\n\\[\n\\bar{X}\\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} = 5.3\\pm 1.96\\frac{1.5}{\\sqrt{10}} = 5.3\\pm 0.93 = \\left[4.37,\\,6.23\\right].\n\\]\nEs decir, \\(\\mu\\) estaría entre \\(4.37\\) y \\(6.23\\) puntos con un 95% de confianza.\n\n\nEjemplo 3.6 La imprecisión del intervalo anterior es de \\(\\pm 0.93\\) puntos.\nSi se desea reducir esta imprecisión a \\(\\pm 0.5\\) puntos, ¿qué tamaño muestral sería necesario?\n\\[\nn = 4 z_{\\alpha/2}^2\\frac{\\sigma^2}{A^2} = 4\\cdot 1.96^2\\frac{1.5^2}{(2\\cdot 0.5)^2} = 34.57.\n\\]\nPor tanto, se necesitaría una muestra de al menos 35 estudiantes para conseguir un intervalo del 95% de confianza y una precisión de \\(\\pm 0.5\\) puntos.\n\n\n\n\n3.6.2 Intervalo de confianza para la media de una población normal con varianza desconocida\nSea \\(X\\) una variable aleatoria que cumple las siguientes hipótesis:\n\nSu distribución es normal \\(X\\sim N(\\mu,\\sigma)\\).\nTanto su media \\(\\mu\\) como su varianza \\(\\sigma^2\\) son desconocidas.\n\nCuando se desconoce la varianza poblacional se suele estimar mediante la cuasivarianza \\(\\hat{S}^2\\). Como consecuencia, el estimador de referencia ya no sigue una distribución normal como en el caso de conocer la varianza, sino un T de Student de \\(n-1\\) grados de libertad:\n\\[\n\\left.\n\\begin{array}{l}\n\\bar X \\sim N\\left(\\mu,\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\\n\\displaystyle\\frac{(n-1)\\hat{S}^2}{\\sigma^2}\\sim \\chi^2(n-1)\n\\end{array}\n\\right\\}\n\\Rightarrow\n\\frac{\\bar X -\\mu}{\\hat{S}/\\sqrt{n}}\\sim T(n-1),\n\\]\nComo la distribución T de Student, al igual que la normal, también es simétrica respecto al 0, se pueden tomar dos valores opuestos \\(-t^{n-1}_{\\alpha/2}\\) y \\(t^{n-1}_{\\alpha/2}\\) de manera que\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-t^{n-1}_{\\alpha/2}\\leq \\frac{\\bar X -\\mu}{\\hat{S}/\\sqrt{n}} \\leq t^{n-1}_{\\alpha/2}\\right)\\\\\n&= P\\left(-t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\\leq \\bar X -\\mu \\leq t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\\right)\\\\\n&= P\\left(\\bar X-t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\\leq \\mu \\leq \\bar X t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\\right)\n\\end{align*}\\]\n\nTeorema 3.3 (Intervalo de confianza para la media de una población normal con varianza desconocida) Si \\(X\\sim N(\\mu, \\sigma)\\) con \\(\\sigma\\) desconocida, el intervalo de confianza para la media \\(\\mu\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\bar{X}-t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}},\\bar{X}+t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\\right]\n\\]\no bien\n\\[\n\\bar{X}\\pm t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\n\\]\n\n\n3.6.2.1 Calculo del tamaño muestral para estimar la media de una población normal con varianza desconocida\nAl igual que antes, teniendo en cuenta que la amplitud o imprecisión del intervalo para la media de una población con varianza desconocida es\n\\[\nA= 2 t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\n\\]\nse puede calcular fácilmente el tamaño muestral necesario para conseguir un intervalo de amplitud \\(A\\) con confianza \\(1-\\alpha\\):\n\\[\nA= 2 t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}} \\Leftrightarrow \\sqrt{n}= 2 t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{A},\n\\]\nde donde se deduce\n\\[\n\\color{red}{n = 4 (t^{n-1}_{\\alpha/2})^2\\frac{\\hat{S}^2}{A^2}}\n\\]\nEl único problema, a diferencia del caso anterior en que \\(\\sigma\\) era conocida, es que se necesita \\(\\hat{S}\\), por lo que se suele tomar una muestra pequeña previa para calcularla. Por otro lado, el valor de la T de student suele aproximarse asintóticamente por el de la normal estándar \\(t^{n-1}_{\\alpha/2}\\approx z_{\\alpha/2}\\).\n\nEjemplo 3.7 Supóngase que en el ejemplo anterior no se conoce la varianza poblacional de las puntuaciones.\nTrabajando con la misma muestra de las puntuaciones de 10 estudiantes\n\\[\n4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3\n\\]\nse puede calcular el intervalo de confianza para \\(\\mu\\) con un nivel de confianza \\(1-\\alpha=0.95\\) (nivel de significación \\(\\alpha=0.05\\)):\n\n\\(\\bar X = \\frac{4+\\cdots+3}{10}= \\frac{53}{10} = 5.3\\) puntos.\n\\(\\hat{S}^2= \\frac{(4-5.3)^2+\\cdots+(3-5.3)^2}{9} = 3.5667\\) y \\(\\hat{S}=\\sqrt{3.5667}=1.8886\\) puntos.\n\\(t^{n-1}_{\\alpha/2}=t^9_{0.025}\\) es el valor de la T de Student de 9 grados de libertad, que deja una probabilidad acumulada superior de \\(0.025\\), que vale \\(2.2622\\).\n\nSustituyendo estos valores en la fórmula del intervalo, se tiene\n\\[\n\\bar{X}\\pm t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}} = 5.3\\pm 2.2622\\frac{1.8886}{\\sqrt{10}} = 5.3\\pm 1.351 = \\left[3.949,\\,6.651\\right].\n\\]\n\n\nEjemplo 3.8 Como se puede apreciar, la imprecisión del intervalo anterior es de \\(\\pm 1.8886\\) puntos, que es significativamente mayor que en el caso de conocer la varianza de la población. Esto es lógico pues al tener que estimar la varianza de la población, el error de la estimación se agrega al error del intervalo.\nAhora, el tamaño muestral necesario para reducir la imprecisión a \\(\\pm 0.5\\) puntos es\n\\[\nn = 4 (z_{\\alpha/2})^2\\frac{\\hat{S}^2}{A^2} = 4\\cdot 1.96^2\\frac{3.5667}{(2\\cdot 0.5)^2} = 54.81.\n\\]\nPor tanto, si se desconoce la varianza de la población se necesita una muestra de al menos 55 estudiantes para conseguir un intervalo del 95% de confianza y una precisión de \\(\\pm 0.5\\) puntos.\n\n\n\n\n3.6.3 Intervalo de confianza para la media de una población no normal\nSea \\(X\\) una variable aleatoria que cumple las siguientes hipótesis:\n\nSu distribución no es normal.\nTanto su media \\(\\mu\\) como su varianza \\(\\sigma^2\\) son desconocidas.\n\nSi la población no es normal las distribuciones de los estimadores de referencia cambian, de manera que los intervalos anteriores no son válidos.\nNo obstante, si la muestras es grande (\\(n\\geq 30\\)), de acuerdo al teorema central del límite, la distribución de la media muestral se aproximará a una normal, de modo que sigue siendo cierto\n\\[\n\\bar X \\sim N\\left(\\mu,\\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\nEn consecuencia, sigue siendo válido el intervalo anterior.\n\nTeorema 3.4 (Intervalo de confianza para la media de una población no normal con muestras grandes) Si \\(X\\) es una variable con distribución no normal y \\(n\\geq 30\\), el intervalo de confianza para la media \\(\\mu\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\bar{X}\\pm t^{n-1}_{\\alpha/2}\\frac{\\hat{S}}{\\sqrt{n}}\n\\]\n\n\n\n3.6.4 Intervalo de confianza para la varianza de una población normal\nSea \\(X\\) una variable aleatoria que cumple las siguientes hipótesis:\n\nSu distribución es normal \\(X\\sim N(\\mu,\\sigma)\\).\nTanto su media \\(\\mu\\) como su varianza \\(\\sigma^2\\) son desconocidas.\n\nPara estimar la varianza de una población normal, se parte del estimador de referencia\n\\[\n\\frac{nS^2}{\\sigma^2} = \\frac{(n-1)\\hat{S}^2}{\\sigma^2}\\sim \\chi^2(n-1),\n\\]\nque sigue una distribución chi-cuadrado de \\(n-1\\) grados de libertad.\nSobre esta distribución hay que calcular los valores \\(\\chi_i\\) y \\(\\chi_s\\) tales que\n\\[\nP(\\chi_i\\leq \\chi^2(n-1) \\leq \\chi_s) = 1-\\alpha.\n\\]\nComo la distribución chi-cuadrado no es simétrica respecto al 0, se toman dos valores \\(\\chi^{n-1}_{\\alpha/2}\\) y \\(\\chi^{n-1}_{1-\\alpha/2}\\) que dejen sendas colas de probabilidad acumulada inferior de \\(\\alpha/2\\) y \\(1-\\alpha/2\\) respectivamente.\n\n\n\n\n\nAsí pues, se tiene\n\\[\\begin{align*}\n1-\\alpha &= P\\left(\\chi^{n-1}_{\\alpha/2}\\leq \\frac{nS^2}{\\sigma^2}  \\leq \\chi^{n-1}_{1-\\alpha/2}\\right) =\nP\\left(\\frac{1}{\\chi^{n-1}_{\\alpha/2}}\\geq \\frac{\\sigma^2}{nS^2}  \\geq \\frac{1}{\\chi^{n-1}_{1-\\alpha/2}}\\right)=\\\\\n&= P\\left(\\frac{1}{\\chi^{n-1}_{1-\\alpha/2}}\\leq \\frac{\\sigma^2}{nS^2}  \\leq \\frac{1}{\\chi^{n-1}_{\\alpha/2}}\\right)\n= P\\left(\\frac{nS^2}{\\chi^{n-1}_{1-\\alpha/2}}\\leq \\sigma^2  \\leq \\frac{nS^2}{\\chi^{n-1}_{\\alpha/2}}\\right).\n\\end{align*}\\]\nPor tanto, el intervalo de confianza para la varianza de una población normal es:\n\nTeorema 3.5 (Intervalo de confianza para la varianza de una población normal) Si \\(X\\sim N(\\mu, \\sigma)\\) con \\(\\sigma\\) conocida, el intervalo de confianza para la varianza \\(\\sigma^2\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\frac{nS^2}{\\chi^{n-1}_{1-\\alpha/2}},\\frac{nS^2}{\\chi^{n-1}_{\\alpha/2}}\\right]\n\\]\n\n\nEjemplo 3.9 Siguiendo con el ejemplo de las puntuaciones en un examen, si se quiere estimar la varianza a partir de la muestra:\n\\[\n4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3\n\\]\npara el intervalo de confianza para \\(\\sigma^2\\) con un nivel de confianza \\(1-\\alpha=0.95\\) (nivel de significación \\(\\alpha=0.05\\)) se tiene:\n\n\\(S^2= \\frac{(4-5.3)^2+\\cdots+(3-5.3)^2}{10} = 3.21\\) puntos\\(^2\\).\n\\(\\chi^{n-1}_{\\alpha/2}=\\chi^9_{0.025}\\) es el valor de la chi-cuadrado de 9 grados de libertad, que deja una probabilidad acumulada inferior de \\(0.025\\), y vale \\(2.7\\).\n\\(\\chi^{n-1}_{1-\\alpha/2}=\\chi^9_{0.975}\\) es el valor de la chi-cuadrado de 9 grados de libertad, que deja una probabilidad acumulada inferior de \\(0.975\\), y vale \\(19\\).\n\nSustituyendo estos valores en la fórmula del intervalo, se llega a\n\\[\n\\left[\\frac{nS^2}{\\chi^{n-1}_{1-\\alpha/2}},\\frac{nS^2}{\\chi^{n-1}_{\\alpha/2}}\\right] =\n\\left[\\frac{10\\cdot 3.21}{19},\\frac{10\\cdot 3.21}{2.7}\\right] = [1.69,\\,11.89] \\text{ puntos}^2.\n\\]\n\n\n\n3.6.5 Intervalo de confianza para una proporción\nPara estimar la proporción \\(p\\) de individuos de una población que presentan una determinada característica, se parte de la variable que mide el número de individuos que la presentan en una muestra de tamaño \\(n\\). Dicha variable sigue una distribución binomial\n\\[\nX\\sim B(n,p)\n\\]\nComo ya se vio, si el tamaño muestral es suficientemente grande (en realidad basta que se cumpla \\(np\\geq 5\\) y \\(n(1-p)\\geq 5\\)), el teorema central de límite asegura que \\(X\\) tendrá una distribución aproximadamente normal\n\\[\nX\\sim N(np,\\sqrt{np(1-p)}).\n\\]\nEn consecuencia, la proporción muestral \\(\\hat p\\) también será normal\n\\[\n\\hat{p}=\\frac{X}{n} \\sim N\\left(p,\\sqrt{\\frac{p(1-p)}{n}}\\right),\n\\]\nque es el estimador de referencia.\nTrabajando con la distribución del estimador de referencia\n\\[\n\\hat p\\sim N\\left(p,\\sqrt{\\frac{p(1-p)}{n}}\\right)\n\\]\ntras tipificar, se pueden encontrar fácilmente, al igual que hicimos antes, valores \\(-z_{\\alpha/2}\\) y \\(z_{\\alpha/2}\\) que cumplan\n\\[\nP\\left(-z_{\\alpha/2}\\leq \\frac{\\hat p-p}{\\sqrt{p(1-p)/n}}\\leq z_{\\alpha/2} \\right) = 1-\\alpha.\n\\]\nAsí pues, deshaciendo la tipificación y razonando como antes, se tiene\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-z_{\\alpha/2}\\leq \\frac{\\hat p-p}{\\sqrt{p(1-p)/n}}\\leq z_{\\alpha/2} \\right) \\\\\n&= P\\left(-z_{\\alpha/2}\\frac{\\sqrt{p(1-p)}}{n}\\leq \\hat p-p\\leq z_{\\alpha/2}\\frac{\\sqrt{p(1-p)}}{n} \\right) \\\\\n&= P\\left(\\hat{p}-z_{\\alpha/2}\\frac{\\sqrt{p(1-p)}}{n}\\leq p\\leq \\hat{p}+z_{\\alpha/2}\\frac{\\sqrt{p(1-p)}}{n} \\right)\n\\end{align*}\\]\nPor tanto, el intervalo de confianza para una proporción es\n\nTeorema 3.6 (Intervalo de confianza para una proporción) Si \\(X\\sim B(n,p)\\), y se cumple que \\(np\\geq 5\\) y \\(n(1-p)\\geq 5\\), entonces el intervalo de confianza para la proporción \\(p\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\hat{p}-z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}},\\hat{p}+z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\right]\n\\]\no bien\n\\[\n\\hat{p}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]\n\n\n3.6.5.1 Cálculo del tamaño muestra para estimar una proporción\nLa amplitud o imprecisión del intervalo para la proporción de una población es\n\\[\nA= 2 z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]\nasí que se puede calcular fácilmente el tamaño muestral necesario para conseguir un intervalo de amplitud \\(A\\) con confianza \\(1-\\alpha\\):\n\\[\nA= 2 z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\Leftrightarrow A^2= 4 z_{\\alpha/2}^2\\frac{\\hat{p}(1-\\hat{p})}{n},\n\\]\nde donde se deduce\n\\[\n\\color{red}{n= 4 z_{\\alpha/2}^2\\frac{\\hat{p}(1-\\hat{p})}{A^2}}\n\\]\nPara poder hacer el cálculo se necesita una estimación de la proporción \\(\\hat{p}\\), por lo que suele tomarse una muestra previa pequeña para calcularla. En el peor de los casos, si no se dispone de una muestra previa, puede tomarse \\(\\hat{p}=0.5\\).\n\nEjemplo 3.10 Supóngase que se quiere estimar la proporción de fumadores que hay en una determinada población. Para ello se toma una muestra de 20 personas y se observa si fuman (1) o no (0):\n\\[\n0 - 1 - 1 - 0 - 0 - 0 - 1 - 0 - 0 - 1 - 0 - 0 - 0 - 1 - 1- 0 - 1 - 1 - 0 - 0\n\\]\nEntonces:\n\n\\(\\hat p=\\frac{8}{20}=0.4\\), por tanto, se cumple \\(np=20\\cdot 0.4 = 8\\geq 5\\) y \\(n(1-p)=20\\cdot 0.6= 12\\geq 5\\).\n\\(z_{\\alpha/2}=z_{0.025}\\) es el valor de la normal estándar que deja una probabilidad acumulada superior de \\(0.025\\), que vale aproximadamente \\(1.96\\).\n\nSustituyendo estos valores en la fórmula del intervalo, se tiene\n\\[\n\\hat{p}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = 0.4\\pm 1.96\\sqrt{\\frac{0.4\\cdot 0.6}{10}} = 0.4\\pm  0.3 = \\left[0.1,\\,0.7\\right].\n\\]\nEs decir, \\(p\\) estaría entre \\(0.1\\) y \\(0.7\\) con un 95% de confianza.\n\n\nEjemplo 3.11 Como se puede apreciar la imprecisión del intervalo anterior es \\(\\pm 0.3\\), que es enorme teniendo en cuenta que se trata de un intervalo para una proporción.\nPara conseguir intervalos precisos para estimar proporciones se necesitan tamaños muestrales bastante grandes. Si por ejemplo se quiere una precisión de \\(\\pm 0.05\\), el tamaño muestral necesario sería:\n\\[\nn= 4 z_{\\alpha/2}^2\\frac{\\hat{p}(1-\\hat{p})}{A^2}=4\\cdot 1.96^2\\frac{0.4\\cdot 0.6}{(2\\cdot0.05)^2}= 368.79.\n\\]\nEs decir, se necesitarían al menos 369 individuos para conseguir un intervalo para la proporción con una confianza del \\(95\\%\\)."
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-para-la-comparación-dos-poblaciones",
    "href": "07-estimacion.html#intervalos-de-confianza-para-la-comparación-dos-poblaciones",
    "title": "3  Estimación de parámetros poblacionales",
    "section": "3.7 Intervalos de confianza para la comparación dos poblaciones",
    "text": "3.7 Intervalos de confianza para la comparación dos poblaciones\nEn muchos estudios el objetivo en sí no es averiguar el valor de un parámetro, sino compararlo con el de otra población. Por ejemplo, comparar si un determinado parámetro vale lo mismo en la población de hombres y en la de mujeres.\nEn estos casos no interesa realmente estimar los dos parámetros por separado, sino hacer una estimación que permita su comparación.\nSe verán tres casos:\n\nComparación de medias: Se estima la diferencia de medias \\(\\mu_1-\\mu_2\\).\nComparación de varianzas: Se estima la razón de varianzas \\(\\displaystyle \\frac{\\sigma^2_1}{\\sigma^2_2}\\).\nComparación de proporciones: Se estima la diferencia de proporciones \\(\\hat p_1-\\hat p_2\\).\n\nA continuación se presentan los siguientes intervalos de confianza para la comparación de dos poblaciones:\n\nIntervalo para la diferencia de medias de dos poblaciones normales con varianzas conocidas.\nIntervalo para la diferencia de medias de dos poblaciones normales con varianzas desconocidas pero iguales.\nIntervalo para la diferencia de medias de dos poblaciones normales con varianzas desconocidas y diferentes.\nIntervalo para el cociente de varianzas de dos poblaciones normales.\nIntervalo para la diferencia de proporciones de dos poblaciones.\n\n\n3.7.1 Intervalo de confianza para la diferencia de medias de poblaciones normales con varianzas conocidas\nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias que cumplen las siguientes hipótesis:\n\nSu distribución es normal \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\).\nSus medias \\(\\mu_1\\) y \\(\\mu_2\\) son desconocidas, pero sus varianzas \\(\\sigma^2_1\\) y \\(\\sigma^2_2\\) son conocidas.\n\nBajo estas hipótesis, si se toman dos muestras independientes, una de cada población, de tamaños \\(n_1\\) y \\(n_2\\) respectivamente, la diferencia de las medias muestrales sigue una distribución normal\n\\[\n\\left.\n\\begin{array}{l}\n\\bar{X}_1\\sim N\\left(\\mu_1,\\frac{\\sigma_1}{\\sqrt{n_1}} \\right)\\\\\n\\bar{X}_2\\sim N\\left(\\mu_2,\\frac{\\sigma_2}{\\sqrt{n_2}} \\right)\n\\end{array}\n\\right\\}\n\\Rightarrow\n\\bar{X}_1-\\bar{X}_2 \\sim N\\left(\\mu_1-\\mu_2,\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\right).\n\\]\nA partir de aquí, tipificando, se pueden buscar los valores de la normal estándar \\(-z_{\\alpha/2}\\) y \\(z_{\\alpha/2}\\) que cumplen:\n\\[\nP\\left(-z_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}} \\leq z_{\\alpha/2}\\right) = 1-\\alpha.\n\\]\nY deshaciendo la tipificación, se tiene\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-z_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}} \\leq z_{\\alpha/2}\\right) \\\\\n&= P\\left(-z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\leq (\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)\\leq z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\right) \\\\\n&= P\\left(\\bar{X}_1-\\bar{X}_2 - z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\leq \\mu_1-\\mu_2\\leq \\bar{X}_1-\\bar{X}_2 + z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\right)\n\\end{align*}\\]\nAsí pues, el intervalo de confianza para la diferencia de medias es\n\nTeorema 3.7 (Intervalo de confianza para la diferencia de medias de poblaciones normales con varianzas conocidas) Si \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\), con \\(\\sigma_1\\) y \\(\\sigma_2\\) conocidas, el intervalo de confianza para la diferencia de medias \\(\\mu_1-\\mu_2\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\bar{X}_1-\\bar{X}_2-z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}},\\bar{X}_1-\\bar{X}_2+z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\right]\n\\]\no bien\n\\[\n\\bar{X}_1-\\bar{X}_2\\pm z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\n\\]\n\n\n\n3.7.2 Intervalo de confianza para la diferencia de medias de dos poblaciones normales con varianzas desconocidas e iguales\nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias que cumplen las siguientes hipótesis:\n\nSu distribución es normal \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\).\nSus medias \\(\\mu_1\\) y \\(\\mu_2\\) son desconocidas y sus varianzas también, pero son iguales \\(\\sigma^2_1=\\sigma^2_2=\\sigma^2\\).\n\nCuando se desconoce la varianza poblacional se puede estimar a partir de las muestras de tamaños \\(n_1\\) y \\(n_2\\) de ambas poblaciones mediante la cuasivarianza ponderada:\n\\[\n\\hat{S}^2_p = \\frac{n_1S^2_1+n_2S^2_2}{n_1+n_2-2}.\n\\]\nEl estimador de referencia en este caso sigue una distribución T de Student:\n\\[\n\\left.\n\\begin{array}{l}\n\\bar{X}_1-\\bar{X}_2\\sim N\\left(\\mu_1-\\mu_2,\\sigma\\sqrt{\\frac{n_1+n_2}{n_1n_2}} \\right)\\\\\n\\displaystyle \\frac{n_1S_1^2+n_2S_2^2}{\\sigma^2} \\sim \\chi^2(n_1+n_2-2)\n\\end{array}\n\\right\\}\n\\Rightarrow\n\\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}} \\sim T(n_1+n_2-2).\n\\]\nA partir de aquí, se pueden buscar los valores de la T de Student \\(-t^{n_1+n_2-2}_{\\alpha/2}\\) y \\(t^{n_1+n_2-2}_{\\alpha/2}\\) que cumplen\n\\[\nP\\left(-t^{n_1+n_2-2}_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}}\n\\leq t^{n_1+n_2-2}_{\\alpha/2}\\right) = 1-\\alpha.\n\\]\nY deshaciendo la transformación se tiene\n\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-t^{n_1+n_2-2}_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}} \\leq t^{n_1+n_2-2}_{\\alpha/2}\\right) \\\\\n&= P\\left(-t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\\leq (\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2) \\leq t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\\right) \\\\\n&= P\\left(\\bar{X}_1-\\bar{X}_2 - t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\\leq \\mu_1-\\mu_2 \\leq \\bar{X}_1-\\bar{X}_2 + t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\\right).\n\\end{align*}\\]\n\nAsí pues, el intervalo de confianza para la diferencia de medias es\n\nTeorema 3.8 (Intervalo de confianza para la diferencia de medias de poblaciones normales con varianzas desconocidas iguales) Si \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\), con \\(\\sigma_1 = \\sigma_2\\) desconocidas, el intervalo de confianza para la diferencia de medias \\(\\mu_1-\\mu_2\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[\\bar{X}_1-\\bar{X}_2-t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}},\\bar{X}_1-\\bar{X}_2+t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\\right]\n\\]\no bien\n\\[\n\\bar{X}_1-\\bar{X}_2\\pm t^{n_1+n_2-2}_{\\alpha/2}\\hat{S}_p\\sqrt{\\frac{n_1+n_2}{n_1n_2}}\n\\]\n\nSi \\([l_i,l_s]\\) es un intervalo de confianza de nivel \\(1-\\alpha\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\), entonces\n\\[\n\\mu_1-\\mu_2 \\in [l_i,l_s]\n\\]\ncon una confianza del \\(1-\\alpha\\%\\).\nPor consiguiente, según los valores del intervalo de confianza se tiene:\n\nSi todos los valores del intervalo son negativos \\((l_s&lt;0)\\), entonces se puede concluir que \\(\\mu_1-\\mu_2&lt;0\\) y por tanto \\(\\mu_1&lt;\\mu_2\\).\nSi todos los valores del intervalo son positivos \\((l_i&gt;0)\\), entonces se puede concluir que \\(\\mu_1-\\mu_2&gt;0\\) y por tanto \\(\\mu_1&gt;\\mu_2\\).\nSi el intervalo tiene tanto valores positivos como negativos, y por tanto contiene al 0 (\\(0\\in [l_i,l_s])\\), entonces no se puede afirmar que una media sea mayor que la otra. En este caso se suele asumir la hipótesis de que las medias son iguales \\(\\mu_1=\\mu_2\\).\n\nTanto en el primer como en el segundo caso se dice que entre las medias hay diferencias estadísticamente significativas.\n\nEjemplo 3.12 Supóngase que se quiere comparar el rendimiento académico de dos grupos de alumnos, uno con 10 alumnos y otro con 12, que han seguido metodologías diferentes. Para ello se les realiza un examen y se obtienen las siguientes puntuaciones:\n\\[\\begin{align*}\nX_1 &: 4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3 \\\\\nX_2 &: 8 - 9 - 5 - 3 - 8 - 7 - 8 - 6 - 8 - 7 - 5 - 7\n\\end{align*}\\]\nSi se supone que ambas variables tienen la misma varianza, se tiene\n\n\\(\\bar{X}_1 = \\frac{4+\\cdots +3}{10}=5.3\\) y \\(\\bar{X}_2=\\frac{8+\\cdots +7}{12}=6.75\\) puntos.\n\\(S_1^2= \\frac{4^2+\\cdots + 3^2}{10}-5.3^2=3.21\\) y \\(S_2^2= \\frac{8^2+\\cdots +3^2}{12}-6.75^2=2.6875\\) puntos\\(^2\\).\n\\(\\hat{S}_p^2 = \\frac{10\\cdot 3.21+12\\cdot 2.6875}{10+12-2}= 3.2175\\) puntos\\(^2\\), y \\(\\hat S_p=1.7937\\).\n\\(t^{n_1+n_2-2}_{\\alpha/2}=t^{20}_{0.025}\\) es el valor de la T de Student de 20 grados de libertad que deja una probabilidad acumulada superior de \\(0.025\\), y que vale aproximadamente \\(2.09\\).\n\n\nY sustituyendo en la fórmula del intervalo llegamos a\n\\[\n5.3-6.75 \\pm 2.086\\cdot 1.7937\\sqrt{\\frac{10+12}{10\\cdot 12}} = -1.45\\pm 1.6021 = [-3.0521,\\,0.1521] \\text{ puntos}.\n\\]\nEs decir, la diferencia de puntuaciones medias \\(\\mu_1-\\mu_2\\) está entre \\(-3.0521\\) y \\(0.1521\\) puntos con una confianza del \\(95\\%\\).\nA la vista del intervalo se puede concluir que, puesto que el intervalo contiene tanto valores positivos como negativos, y por tanto contiene al 0, no puede afirmarse que una de las medias se mayor que la otra, de modo que se supone que son iguales y no se puede decir que haya diferencias significativas entre los grupos.\n\n\n3.7.3 Intervalo de confianza para la diferencia de medias de dos poblaciones normales con varianzas desconocidas y distintas\nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias que cumplen las siguientes hipótesis:\n\nSu distribución es normal \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\).\nSus medias \\(\\mu_1\\), \\(\\mu_2\\) y varianzas \\(\\sigma_1^2\\), \\(\\sigma_2^2\\), son desconocidas, pero \\(\\sigma^2_1\\neq \\sigma^2_2\\).\n\nEn este caso el estimador de referencia sigue una distribución T de Student\n\\[\n\\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}} \\sim T(g),\n\\]\ndonde el número de grados de libertad es \\(g=n_1+n_2-2-\\Delta\\), siendo\n\\[\n\\Delta =\n\\frac{(\\frac{n_2-1}{n_1}\\hat{S}_1^2-\\frac{n_1-1}{n_2}\\hat{S}_2^2)^2}{\\frac{n_2-1}{n_1^2}\\hat{S}_1^4+\\frac{n_1-1}{n_2^2}\\hat{S}_2^4}.\n\\]\nA partir de aquí, una vez más, se pueden buscar los valores de la T de Student \\(-t^{g}_{\\alpha/2}\\) y \\(t^{g}_{\\alpha/2}\\) que cumplen\n\\[\nP\\left(-t^{g}_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}} \\leq t^{g}_{\\alpha/2}\\right) = 1-\\alpha.\n\\]\nY deshaciendo la transformación se llega a\n\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-t^{g}_{\\alpha/2}\\leq \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}} \\leq t^{g}_{\\alpha/2}\\right) \\\\\n&= P\\left(-t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\\leq (\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2) \\leq t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\\right) \\\\\n&= P\\left(\\bar{X}_1-\\bar{X}_2 - t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\\leq\\mu_1-\\mu_2 \\leq \\bar{X}_1-\\bar{X}_2 + t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\\right) \\\\\n\\end{align*}\\]\n\nAsí pues, el intervalo de confianza para la diferencia de medias es\n\nTeorema 3.9 (Intervalo de confianza para la diferencia de medias de poblaciones normales con varianzas desconocidas distintas) Si \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\), con \\(\\sigma_1 \\neq \\sigma_2\\) desconocidas, el intervalo de confianza para la diferencia de medias \\(\\mu_1-\\mu_2\\) con nivel de confianza \\(1-\\alpha\\) es \\[\n\\left[\\bar{X}_1-\\bar{X}_2-t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}},\\bar{X}_1-\\bar{X}_2-t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\\right]\n\\]\no bien\n\\[\n\\bar{X}_1-\\bar{X}_2\\pm t^{g}_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2_1}{n_1}+\\frac{\\hat{S}^2_2}{n_2}}\n\\]\n\nComo se acaba de ver, existen dos intervalos posibles para estimar la diferencia de medias: uno para cuando las varianzas poblacionales son iguales y otro para cuando no lo son.\nAhora bien, si las varianzas poblacionales son desconocidas,\n\n¿cómo saber qué intervalo utilizar?\n\nLa respuesta está en el próximo intervalo que se verá, que permite estimar la razón de varianzas \\(\\frac{\\sigma_2^2}{\\sigma_1^2}\\) y por tanto, su comparación.\nAsí pues, antes de calcular el intervalo de confianza para la comparación de medias, cuando las varianzas poblacionales sean desconocidas, es necesario calcular el intervalo de confianza para la razón de varianzas y elegir el intervalo para la comparación de medias en función del valor de dicho intervalo.\n\n\n3.7.4 Intervalo de confianza para el cociente de varianzas\nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias que cumplen las siguientes hipótesis:\n\nSu distribución es normal \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\).\nSus medias \\(\\mu_1\\), \\(\\mu_2\\) y varianzas \\(\\sigma_1^2\\), \\(\\sigma_2^2\\) son desconocidas.\n\nEn este caso, para muestras de ambas poblaciones de tamaños \\(n_1\\) y \\(n_2\\) respectivamente, el estimador de referencia sigue una distribución F de Fisher-Snedecor:\n\\[\n\\left.\n\\begin{array}{l}\n\\displaystyle \\frac{(n_1-1)\\hat{S}_1^2}{\\sigma_1^2}\\sim \\chi^2(n_1-1) \\\\\n\\displaystyle \\frac{(n_2-1)\\hat{S}_2^2}{\\sigma_2^2}\\sim \\chi^2(n_2-1)\n\\end{array}\n\\right\\}\n\\Rightarrow\n\\frac{\\frac{\\frac{(n_2-1)\\hat{S}_2^2}{\\sigma_2^2}}{n_2-1}}{\\frac{\\frac{(n_1-1)\\hat{S}_1^2}{\\sigma_1^2}}{n_1-1}} =\n\\frac{\\sigma_1^2}{\\sigma_2^2}\\frac{\\hat{S}_2^2}{\\hat{S}_1^2}\\sim F(n_2-1,n_1-1).\n\\]\nComo la distribución F de Fisher-Snedecor no es simétrica respecto al 0, se toman dos valores \\(f^{n_2-1,n_1-1}_{\\alpha/2}\\) y \\(f^{n_2-1,n_1-1}_{1-\\alpha/2}\\) que dejen sendas colas de probabilidad acumulada inferior de \\(\\alpha/2\\) y \\(1-\\alpha/2\\) respectivamente.\n\n\n\n\n\nAsí pues, se tiene\n\\[\\begin{align*}\n1-\\alpha &= P\\left(f^{n_2-1,n_1-1}_{\\alpha/2}\\leq \\frac{\\sigma_1^2}{\\sigma_2^2}\\frac{\\hat{S}_2^2}{\\hat{S}_1^2}  \\leq\nf^{n_2-1,n_1-1}_{1-\\alpha/2}\\right) = \\\\ &= P\\left(f^{n_2-1,n_1-1}_{\\alpha/2}\\frac{\\hat{S}_1^2}{\\hat{S}_2^2} \\leq\n\\frac{\\sigma_1^2}{\\sigma_2^2}  \\leq f^{n_2-1,n_1-1}_{1-\\alpha/2}\\frac{\\hat{S}_1^2}{\\hat{S}_2^2}\\right)\n\\end{align*}\\]\nPor tanto, el intervalo de confianza para la comparación de varianzas de dos poblaciones normales es\n\nTeorema 3.10 (Intervalo de confianza para el cociente de varianzas de poblaciones normales) Si \\(X_1\\sim N(\\mu_1,\\sigma_1)\\) y \\(X_2\\sim N(\\mu_2,\\sigma_2)\\), el intervalo de confianza para el cociente de varianzas \\(\\sigma_1/\\sigma_2\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\left[f^{n_2-1,n_1-1}_{\\alpha/2}\\frac{\\hat{S}_1^2}{\\hat{S}_2^2},f^{n_2-1,n_1-1}_{1-\\alpha/2}\\frac{\\hat{S}_1^2}{\\hat{S}_2^2}\\right]\n\\]\n\nSi \\([l_i,l_s]\\) es un intervalo de confianza de nivel \\(1-\\alpha\\) para la razón de varianzas \\(\\frac{\\sigma_1^2}{\\sigma_2^2}\\), entonces\n\\[\n\\frac{\\sigma_1^2}{\\sigma_2^2} \\in [l_i,l_s]\n\\]\ncon una confianza del \\(1-\\alpha\\%\\).\nPor consiguiente, según los valores del intervalo de confianza se tiene:\n\nSi todos los valores del intervalo son menores que 1 \\((l_s&lt;1)\\), entonces se puede concluir que \\(\\frac{\\sigma_1^2}{\\sigma_2^2}&lt;1\\) y por tanto \\(\\sigma_1^2&lt;\\sigma_2^2\\).\nSi todos los valores del intervalo son mayores que 1 \\((l_i&gt;1)\\), entonces se puede concluir que \\(\\frac{\\sigma_1^2}{\\sigma_2^2}&gt;1\\) y por tanto \\(\\sigma_1^2&gt;\\sigma_2^2\\).\nSi el intervalo tiene tanto valores mayores como menores que 1, y por tanto contiene al 1 (\\(1\\in [l_i,l_s])\\), entonces no se puede afirmar que una varianza sea mayor que la otra. En este caso se suele asumir la hipótesis de que las varianzas son iguales \\(\\sigma_1^2=\\sigma_2^2\\).\n\n\nEjemplo 3.13 Siguiendo con el ejemplo de las puntuaciones en dos grupos:\n\\[\\begin{align*}\nX_1 &: 4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3 \\\\\nX_2 &: 8 - 9 - 5 - 3 - 8 - 7 - 8 - 6 - 8 - 7 - 5 - 7\n\\end{align*}\\]\nPara calcular el intervalo de confianza para la razón de varianzas con una confianza del \\(95\\%\\), se tiene:\n\n\\(\\bar{X}_1 = \\frac{4+\\cdots +3}{10}=5.3\\) puntos y \\(\\bar{X}_2=\\frac{8+\\cdots +7}{12}=6.75\\) puntos.\n\\(\\hat{S}_1^2= \\frac{(4-5.3)^2+\\cdots + (3-5.3)^2}{9}=3.5667\\) puntos\\(^2\\) y \\(\\hat{S}_2^2= \\frac{(8-6.75)^2+\\cdots + (3-6.75)^2}{11}=2.9318\\) puntos\\(^2\\).\n\\(f^{n_2-1,n_1-1}_{\\alpha/2}=f^{11,9}_{0.025}\\) es el valor de la F de Fisher de 11 y 9 grados de libertad que deja una probabilidad acumulada inferior de \\(0.025\\), y que vale aproximadamente \\(0.2787\\).\n\\(f^{n_2-1,n_1-1}_{1-\\alpha/2}=f^{11,9}_{0.975}\\) es el valor de la F de Fisher de 11 y 9 grados de libertad que deja una probabilidad acumulada inferior de \\(0.975\\), y que vale aproximadamente \\(3.9121\\).\n\n\nSustituyendo en la fórmula del intervalo se llega a\n\\[\n\\left[0.2787\\frac{3.5667}{2.9318},\\, 3.9121\\frac{3.5667}{2.9318}\\right] = [0.3391,\\, 4.7591] \\text{ puntos}^2.\n\\]\nEs decir, la razón de varianzas \\(\\frac{\\sigma_1^2}{\\sigma_2^2}\\) está entre \\(0.3391\\) y \\(4.7591\\) con una confianza del \\(95\\%\\).\nComo el intervalo tiene tanto valores menores como mayores que 1, no se puede concluir que una varianza sea mayor que la otra, y por tanto se mantiene la hipótesis de que ambas varianzas son iguales.\nSi ahora se quisiesen comparar las medias de ambas poblaciones, el intervalo de confianza para la diferencia de medias que habría que tomar es el que parte de la hipótesis de igualdad de varianzas, que precisamente es el que se ha utilizado antes.\n\n\n3.7.5 Intervalo de confianza para la diferencia de proporciones\nPara comparar las proporciones \\(p_1\\) y \\(p_2\\) de individuos que presentan una determinada característica en dos poblaciones independientes, se estima su diferencia \\(p_1-p_2\\).\nSi se toma una muestra de cada población, de tamaños \\(n_1\\) y \\(n_2\\) respectivamente, las variables que miden el número de individuos que presentan la característica en cada una de ellas siguen distribuciones\n\\[\nX_1\\sim B(n_1,p_1)\\quad \\mbox{y}\\quad X_2\\sim B(n_2,p_2)\n\\]\nCuando los tamaños muestrales son grandes (en realidad basta que se cumpla \\(n_1p_1\\geq 5\\), \\(n_1(1-p_1)\\geq 5\\), \\(n_2p_2\\geq 5\\) y \\(n_2(1-p_2)\\geq 5\\)), el teorema central de límite asegura que \\(X_1\\) y \\(X_2\\) tendrán distribuciones normales\n\\[\nX_1\\sim N(n_1p_1,\\sqrt{n_1p_1(1-p_1)}) \\quad \\mbox{y}\\quad X_2\\sim N(n_2p_2,\\sqrt{n_2p_2(1-p_2)}),\n\\]\ny las proporciones muestrales\n\\[\n\\hat{p}_1=\\frac{X_1}{n_1} \\sim N\\left(p_1,\\sqrt{\\frac{p_1(1-p_1)}{n_1}}\\right) \\quad \\mbox{y}\\quad\n\\hat{p}_2=\\frac{X_2}{n_2} \\sim N\\left(p_2,\\sqrt{\\frac{p_2(1-p_2)}{n_2}}\\right)\n\\]\nA partir de las proporciones muestrales se construye el estimador de referencia\n\\[\n\\hat{p}_1-\\hat{p}_2\\sim  N\\left(p_1-p_2,\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}\\right).\n\\]\nTipificando, se buscan valores \\(-z_{\\alpha/2}\\) y \\(z_{\\alpha/2}\\) que cumplan\n\\[\nP\\left(-z_{\\alpha/2}\\leq \\frac{(\\hat{p}_1-\\hat{p_2})-(p_1-p_2)}{\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}}\\leq z_{\\alpha/2} \\right) = 1-\\alpha.\n\\]\nY deshaciendo la tipificación, se llega a\n\n\\[\\begin{align*}\n1-\\alpha\n&= P\\left(-z_{\\alpha/2}\\leq \\frac{(\\hat{p}_1-\\hat{p_2})-(p_1-p_2)}{\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}}\\leq z_{\\alpha/2} \\right) \\\\\n&= P\\left(-z_{\\alpha/2}\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}\\leq (\\hat{p}_1-\\hat{p_2})-(p_1-p_2)\\leq z_{\\alpha/2}\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}} \\right) \\\\\n&= P\\left(\\hat{p}_1-\\hat{p_2} -z_{\\alpha/2}\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}}\\leq \\hat{p}_1-\\hat{p_2} + p_1-p_2\\leq z_{\\alpha/2}\\sqrt{\\frac{p_1(1-p_1)}{n_1}+\\frac{p_2(1-p_2)}{n_2}} \\right)\n\\end{align*}\\]\n\nAsí pues, el intervalo de confianza para la diferencia de proporciones es\n\nTeorema 3.11 (Intervalo de confianza para la diferencia de proporciones) Si \\(X_1\\sim B(n_1,p_1)\\) y \\(X_2\\sim B(n_2,p_2)\\), con \\(n_1p_1\\geq 5\\), \\(n_1(1-p_1)\\geq 5\\), \\(n_2p_2\\geq 5\\) y \\(n_2(1-p_2)\\geq 5\\), el intervalo de confianza para la diferencia de proporciones \\(p_1-p_2\\) con nivel de confianza \\(1-\\alpha\\) es\n\\[\n\\hat{p}_1-\\hat{p}_2\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\n\\]\n\n\nEjemplo 3.14 Supóngase que se quieren comparar las proporciones o porcentajes de aprobados en dos grupos que han seguido metodologías distintas. En el primer grupo han aprobado 24 alumnos de un total de 40, mientras que en el segundo han aprobado 48 de 60.\nPara calcular el intervalo de confianza para la diferencia de proporciones con un nivel de confianza del \\(95\\%\\), se tiene:\n\n\\(\\hat{p}_1=24/40= 0.6\\) y \\(\\hat{p}_2=48/60=0.8\\), de manera que se cumplen las hipótesis \\(n_1\\hat{p}_1=40\\cdot 0.6=24\\geq 5\\), \\(n_1(1-\\hat{p}_1)=40(1-0.6)=26\\geq 5\\), \\(n_2\\hat{p}_2=60\\cdot 0.8 =48\\geq 5\\) y \\(n_2(1-\\hat{p}_2)=60(1-0.8)=12\\geq 5\\).\n\\(z_{\\alpha/2}=z_{0.025}= 1.96\\).\n\nSustituyendo en la fórmula del intervalo se tiene\n\\[\n0.6-0.8\\pm 1.96 \\sqrt{\\frac{0.6(1-0.6)}{40}+\\frac{0.8(1-0.8)}{60}} = -0.2\\pm 0.17 = [-0.37,\\, -0.03].\n\\]\nComo el intervalo es negativo se tiene \\(p_1-p_2&lt;0\\Rightarrow p_1&lt;p_2\\), y se puede concluir que hay diferencias significativas en el porcentaje de aprobados."
  }
]